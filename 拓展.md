*存储过程与函数的区别：**

存储存储过程是一段代码（过程），存储在数据库中的SQL组成。一个存储过程通常用于完成一段业务逻辑，例如报名，交班费，订单入库等。
函数通常是数据库已定义的方法。存储过程和函数事先进行过编译。存储过程和函数执行不是由程序调用，也不是手动启动。而是由事件触发、激活从而实现执行。而一个函数通常专注与某个功能，视为其他程序服务的，需要在其他语句中调用函数才可以，而存储过程不能被其他调用，是自己执行通过call执行。
存储过程和函数都是属于某个数据库。

1，返回值的区别：函数有一个返回值，而存储过程是通过参数返回的，可以有多个或者没有。

2，调用区别：函数可以在查询语句中直接调用（SELECT调用），而存储过程必须单独调用（ EXECUTE 语句执行）。

3，函数一般情况下是用来计算并返回一个计算结果，而存储过程一般是用来完成特定的数据操作（比如修改插入数据库或执行某些DDL语句等等）。

4，oracle中存储过程和函数都可以返回值，但是函数必须要返回值并且一般返回一个值，而存储过程则没有这个限制。

##### 存储过程：

###### **MySQL创建调用**

**创建：**

```sql
create procedure 存储过程名称（in|out|inout 参数名称 参数类型，……）
begin
过程体;
end
```

1、查询

查询所有存储过程状态

```sql
show procedure status;
```

查看对应数据库下所有存储过程状态

```sql
show procedure status where db="数据库名";
```

查看名称包含Student的存储过程状态

```sql
show procedure status where name like "%Student%";
```

查询存储过程详细代码

```sql
show create procedure 过程名;
```

2、修改

```sql
alter procedure 过程名([过程参数[,…]])过程体；
```

3、删除

```sql
drop procedure 过程名；
```

注：不能在一个存储过程中删除另一个存储过程，只能调用另一个存储过程。

**调用存储过程**

mysql存储过程用call和过程名以及一个括号，括号里面根据需要，加入参数，参数包括输入参数、输出参数、输入输出参数调用。

```sql
call 存储过程名（[过程参数[,...]]）
```

###### **Oracle创建调用**

```plsql
create or replace procedure sample_proc 
as  --声明
 msg varchar2(50);
begin  --执行
  msg:='Hello world';--为参数赋值
  dbms_output.put_line('你好的英文为:'||msg);--输出参数
exception --存贮过程异常
  ;
end;
 
--有三种执行语法
--执行语法1
call sample_proc();
--执行结果
sample_proc ) 成功。
你好的英文为:Hello world
 
--执行语法2
exec sample_proc;
--执行结果
匿名块已完成
你好的英文为:Hello world
 
--执行语法3
set serveroutput on
begin
 sample_proc;
end;
--执行结果
匿名块已完成
你好的英文为:Hello world
```

##### **函数**

###### **MySQL创建**

```plsql
DELIMITER $$ --定义结束符。MySQL默认的结束符是分号，但是函数体中可能用到分号。为								了避免冲突，需要另外定义结束符。

DROP FUNCTION IF EXISTS function_name$$ --如果函数genPerson已经存在了，就删除掉。

CREATE FUNCTION function_name(name varchar(20)) RETURNS varchar(50) --创建函数genPerson，函数的参数是name，返回值是varchar(50)。

BEGIN --函数体放在BEGIN 与 END之间。

  DECLARE str VARCHAR(50) DEFAULT ''; --DECLARE声明变量，str类型是varchar(50)，默认值是空。
  SET @tableName=name;
  SET str=CONCAT('create table ', @tableName,'(id int, name varchar(20));'); 
  --CONCAT连接多个字符串。
  
  return str; --RETURN 返回拼接后的字符串str。
END $$
DELIMITER ;

```

###### Oracle**创建**

```plsql
CREATE [OR REPLACE] FUNCTION function_name
   [ (parameter [,parameter]) ]

   RETURN return_datatype

IS | AS

   [declaration_section]

BEGIN
   executable_section

[EXCEPTION
   exception_section]

END [function_name];
```

**执行：**

```plsql
--调用
select function_name('参数');

--删除
DROP FUNCTION function_name;
```

#### **定时器：**

###### **MySQL创建**

```plsql
CREATE EVENT IF NOT EXISTS 计划名
	-- 计划频率和开启计划时间或者是计划执行的时间
	-- 前一个可以实现持续的计划调度，后一个到指定时间进行调度,执行完结束，没有持续性
	ON SCHEDULE [EVERY 10 SECOND STARTS TIMESTAMP 开启时间] [AT 开启时间]
	-- 当计划执行完成时，是否删除
	ON COMPLETION [NOT] PRESERVE 
	do call 存储过程
```

**查看数据库是否开启调度**

```sql
-- 查看是否开启调度
show variables like '%event_scheduler%';
-- value为OFF，未开启；
-- 开启
SET GLOBAL event_scheduler = 1;
```

**关闭和开启指定定时器**

```sql
ALTER EVENT 定时器名 ON  COMPLETION PRESERVE [ENABLE][DISABLE];
-- 开启ENABLE，关闭DISABLE 
```

**删除定时器**

```sql
drop EVENT 定时器名;
```

###### Oracle创建

```plsql
DECLARE  job_test  number;  -- DECLARE 用来定义unlockTest_timer 的定时器编号
BEGIN
  SYS.DBMS_JOB.SUBMIT(
    job => unlockTest_timer,   --job 指的是定时器编号，在DECLARE 中已经声明
    what => 'pro_test;',       --what 指的是要执行的存储过程，也就是SQL语句
    NEXT_DATE => sysdate,      --next_date 指的是下次执行时间
    INTERVAL => 'sysdate+1/（24*60）'  --interval 指的是每次执行时间的间隔时间   这里是一分钟执行一次
  );
Commit;
End;
```

```plsql
--定时器创建好后，会自动执行。
--查看在执行的定时器，job-定时器编号
SELECT job, next_date, next_sec, failures, broken FROM user_jobs;
```

```plsql
--停止
    begin
       dbms_job.broken(定时器编号,true);
       commit;
    end;

--停止后再启动

   begin
        dbms_job.run(定时器编号）;
        commit;
   end;

--定时器删除
   begin
       dbms_job.remove(定时器编号);
       commit;
    end;
```



#### 触发器：

- **触发器组成**

  1、触发事件
  　　DML或DDL语句。
  2、触发时间
  　　是在触发事件发生之前(before) 还是之后(after) 触发
  3、触发操作
  　　使用PL/SQL块进行相应的数据库操作
  4、触发对象
  　　表、视图、模式、数据库
  5、触发频率
  　　触发器内定义的动作被执行的次数，包括语句级和行级。

![1608258987277](D:\AppData\Roaming\Typora\typora-user-images\1608258987277.png)

![1608260588089](D:\AppData\Roaming\Typora\typora-user-images\1608260588089.png)

语句级触发器；DML操作 insert delete update select
 	行级触发器；
  	系统事件触发器；数据库的关闭启动

用户事件触发器；DDL操作 drop alter create

###### MySQL

MySQL的触发器是按照BEFORE触发器、行操作、AFTER触发器的顺序执行的，其中任何一步发生错误都不会继续执行剩下的操作。如果是对事务表进行的操作，那么会整个作为一个事务被回滚，但是如果是对非事务表进行的操作，那么已经更新的记录将无法回滚，这也是设计触发器的时候需要注意的问题。

```plsql
CREATE

    [DEFINER = { user | CURRENT_USER }]

    TRIGGER trigger_name      --trigger_name：触发器的名称，不能与已经存在的触发器重复；

    trigger_time trigger_event   --trigger_time：{ BEFORE | AFTER }，表示在事件之前或之后触发；trigger_event:：{ INSERT |UPDATE | DELETE }，触发该触发器的具体事件；

    ON tbl_name FOR EACH ROW

    trigger_body   --tbl_name：该触发器作用在tbl_name上；
```

```plsql
SHOW TRIGGERS trigger_name;--命令查看触发器
DROP TRIGGER trigger_name;--删除
```

###### Oracle

触发器：类似于AOP（面向切面编程）中的拦截器；不能传递参数，输出参数，也不能显示调用，只有满足触发器条件时会由Oracle自动调用。

- **限制**

  1、触发器不接受参数
  2、一个表上最多可有12个触发器，但同一时间、同一事件、同一类型的触发器只能有一个。并各触发器之间不能有矛盾。
  3、一个表上的触发器越多，该表上的DM操作的性能影响就越大
  4、触发器代码的大小不能超过32K。如需要大量的代码创建触发器，则首先创建过程，然后在触发器中使用CALL语句调用过程
  5、触发器代码只能包含SELECT、INSERT、UPDATE和DELETE语句，
  6、不能包含DDL语句(CREATE、ALTER和DROP) 和事务控制语句（COMMIT、ROLLBACK和SAVEPOINT）

- **创建dml触发器**

  **语句触发器**
  1、语句触发器是指当执行DML语句时被隐含执行的触发器
  2、如果在表上针对某种DML操作创建了语句触发器，则当执行DML操作时会自动地执行触发器的相应代码
  3、为了审计DML操作，或者确保DML操作安全执行时，可以使用语句触发器

  触发器用途很多，例如用户清算购物车后将会触发待收货的数据库

```plsql
--创建触发器
create or replace trigger tri_test
before--触发之前
update or delete--更新或删除
on emp
for each row--对行进行操作
  begin
    dbms_output.put_line(:old.sal);--old表示数据库旧值
    insert into demo(id) values (:new.sal);--new新值
  end;

update emp set sal=888 where empno=7788;
commit;
--代码解释：先执行创建触发器代码后，再执行最后的更新语句。当更新恩平、表后将会输出数据库中本来存放的值，并且触发添加语句在demo表中插入一条语句。


--查询
select * from 表 where object_type='TRIGGER';
--删除
drop trigger ...;
drop trigger ...;
```



#### 定时任务：

###### [MySQL](https://blog.csdn.net/chenshun123/article/details/79677193?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control)

自 MySQL5.1.6起，增加了一个非常有特色的功能–事件调度器(Event Scheduler)，可以用做定时执行某些特定任务，来取代原先只能由操作系统的计划任务来执行的工作。事件调度器有时也可称为临时触发器(temporal triggers)，因为事件调度器是基于特定时间周期触发来执行某些任务，而触发器(Triggers)是基于某个表所产生的事件触发的，区别也就在这里。

```sql
--在使用这个功能之前必须确保 event_scheduler 已开启，可执行 :
mysq> SET GLOBAL event_scheduler = 1;
# 或
mysql> SET GLOBAL event_scheduler = ON;

也可以在配置文件中添加设置 : event_scheduler=1
也可以直接在启动命令加上 : --event_scheduler=1

--查看当前是否已开启事件调度器 :
mysql> SHOW VARIABLES LIKE 'event_scheduler';

# 或
mysql> SELECT @@event_scheduler;

# 或
mysql> SHOW PROCESSLIST;

--创建事件(CREATE EVENT)
CREATE EVENT [IFNOT EXISTS] event_name
  ON SCHEDULE schedule
  [ON COMPLETION [NOT] PRESERVE] --设置这个事件是执行一次还是持久执行，默认为 NOT PRESERVE
  [ENABLE | DISABLE] --可设置该事件创建后状态是否开启或关闭，默认为ENABLE
  [COMMENT 'comment'] --可以给该事件加上注释
  DO sql_statement;

--修改事件(ALTER EVENT)
ALTER EVENT event_name
  [ON SCHEDULE schedule]
  [RENAME TO new_event_name]
  [ON COMPLETION [NOT] PRESERVE]
  [COMMENT 'comment']
  [ENABLE | DISABLE]
  [DO sql_statement]
  
--临时关闭事件
mysql> ALTER EVENT e_test DISABLE;
# 开启事件
mysql> ALTER EVENT e_test ENABLE;

--删除事件(DROP EVENT)
DROP EVENT [IF EXISTS] event_name
```

###### [Oracle](https://blog.csdn.net/qq_40709468/article/details/81876828?ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522160826139016780277846162%252522%25252C%252522scm%252522%25253A%25252220140713.130102334..%252522%25257D&request_id=160826139016780277846162&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-1-81876828.nonecase&utm_term=Oracle%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA)

```plsql
--创建job
begin
  sys.dbms_job.submit(job => 1,        --代表的是号码，第几个定时任务
       what => 'sys_mailing_list_job;',  --这个是调用的你想使用的存储过程切记要打；不然会报错
       next_date => to_date('20-08-2018 14:05:00', 'dd-mm-yyyy hh24:mi:ss'),  --这个是下次调用的时间 
       interval => 'trunc(sysdate,''hh'')+(60+5)/(24*60)');
  commit;    --这个是间隔时间 。我这个代表的是每个小时的过5 比如 1:05,2:05,3:05...24小时的
end;

--删除
job: dbms_job.remove(jobno); -- jobno就是你得任务号 

--修改要执行的操作: 
job:dbms_job.what(jobno, what);   --指定任务号以及存储过程

--修改下次执行时间：
dbms_job.next_date(jobno, next_date);  --指定任务号的时间

--修改间隔时间：
dbms_job.interval(jobno, interval);   --指定任务号的间隔时间

--启动job: 
dbms_job.run(jobno);    --指定任务号启动

--停止job: 
dbms.broken(jobno, broken, nextdate); --broken为boolean值 N代表启动，Y代表没启动（STOP）
```



#### [Linux ：](https://blog.csdn.net/weixin_44895651/article/details/105289038?ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522160825080916780265399902%252522%25252C%252522scm%252522%25253A%25252220140713.130102334..%252522%25257D&request_id=160825080916780265399902&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_yy~default-1-105289038.nonecase&utm_term=linux)

[命令手册](https://blog.csdn.net/p1279030826/article/details/106546972?ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522160826328016780274045083%252522%25252C%252522scm%252522%25253A%25252220140713.130102334..%252522%25257D&request_id=160826328016780274045083&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-106546972.nonecase&utm_term=linux%E5%91%BD%E4%BB%A4%E6%89%8B%E5%86%8C)

```markdown
运行jar包：java -jar
后台运行jar项目：nohup java -jar babyshark-0.0.1-SNAPSHOT.jar  > log.file  2>&1 &
上面的2 和 1 的意思如下:
0    标准输入（一般是键盘）
1    标准输出（一般是显示屏，是用户终端控制台）
2    标准错误（错误信息输出）
将运行的jar 错误日志信息输出到log.file文件中，然后（>&1）就是继续输出到标准输出(前面加的&，是为了让系统识别是标准输出)，最后一个&,表示在后台运行。
后台进程：netstat -anp
查看日志全文：cat + 日志名称.log

实时查看日志：tail -f +日志名称.log
模糊查询日志：grep -r -200 "查询内容" 日志名称.log

查看进程：
ps命令
-a，查看所有
-u，以用户（user）的格式显示
-x, 显示后台进程运行参数
-ef，以全格式显示进程所有信息，包括父进程Pid，创建人，创建时间，进程号。等等
 ps -l   列出与本次登录有关的进程信息；
 ps -aux   查询内存中进程信息；
 ps -aux | grep ...  查询...进程的详细信息；
 top   查看内存中进程的动态信息；
 kill -9 pid   杀死进程。

1：文件管理
ls命令 – 显示指定工作目录下的内容及属性信息
mkdir命令 – 创建目录
cp命令 – 复制文件或目录
mv命令 – 移动或改名文件
pwd命令 – 显示当前路径
2：文档编辑
cat命令 – 在终端设备上显示文件内容
echo命令 – 输出字符串或提取Shell变量的值
rm命令 – 移除文件或目录
tail命令 – 查看文件尾部内容
rmdir命令 – 删除空目录
3：系统管理
startx命令 – 初始化X-windows
rpm命令 – RPM软件包管理器
vmstat命令 – 显示虚拟内存状态
find命令 – 查找和搜索文件
uname命令 – 显示系统信息
4：磁盘管理
df命令 – 显示磁盘空间使用情况
fdisk命令 – 磁盘分区
hdparm命令 – 显示与设定硬盘参数
lsblk命令 – 查看系统的磁盘
vgextend命令 – 扩展卷组
5：文件传输
tftp命令 – 上传及下载文件
curl命令 – 文件传输工具
fsck命令 – 检查并修复Linux文件系统
ftpwho命令 – 显示ftp会话信息
lprm命令 – 删除打印队列中的打印任务
6：网络通讯
ssh命令 – 安全连接客户端
ping命令 – 测试主机间网络连通性
netstat命令 – 显示网络状态
ifconfig命令 – 显示或设置网络设备
ss命令 – 显示活动套接字信息
7：设备管理
mount命令 – 文件系统挂载
MAKEDEV命令 – 建立设备
setleds命令 – 设定键盘上方三个 LED 的状态
lspci命令 – 显示当前设备所有PCI总线信息
sensors命令 – 检测服务器内部温度及电压
8：备份压缩
zipinfo命令 – 查看压缩文件信息
unarj命令 – 解压.arj文件
gzip命令 – 压缩和解压文件
zip命令 – 压缩文件
unzip命令 – 解压缩zip文件
9：其他命令
hash命令 – 显示与清除命令运行时查询的哈希表
bc命令 – 浮点运算
wait命令 – 等待指令
rmmod命令 – 删除模块
history命令 – 显示与操纵历史命令











```



#### [Docker](https://blog.csdn.net/lqpf199681/article/details/110518692?ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522160827066716780261944216%252522%25252C%252522scm%252522%25253A%25252220140713.130102334..%252522%25257D&request_id=160827066716780261944216&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-110518692.nonecase&utm_term=Docker)：

##### 一.Docker介绍

> Docker 是一个开源的应用容器引擎，基于 [Go 语言](https://www.runoob.com/go/go-tutorial.html) 并遵从 Apache2.0 协议开源。
>
> Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。
>
> 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。
>
> Docker 从 17.03 版本之后分为 CE（Community Edition: 社区版） 和 EE（Enterprise Edition: 企业版）。

##### 二.Docker的基本操作

##### 2.1基本准备

这篇文章中我的运行环境都是在CentOS7中运行。

配套视频: [2020 Docker最新超详细版教程通俗易懂](https://www.bilibili.com/video/BV1sK4y1s7Cj)

##### 2.2安装Docker

```sh
# 1.下载关于Docker的依赖环境
yum -y install yum-utils device-mapper-persistent-data lvm2
```

------

```sh
# 2.设置下载Docker的镜像源
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
```

------

```sh
# 3.安装Docker
yum makacache fast
yum -y install docker-ce
```

------

```sh
# 4.启动Docker，并设置为开机自动启动，测试
# 启动Docker服务
systemctl start docker
# 设置开机自动启动
systemctl enable docker
# 测试
docker run hello-world
```

##### 2.3 Docker的中央仓库

> 1. Docker官方的中央仓库: 这个仓库是镜像最全的，但是下载速度较慢。
>    https://hub.docker.com/
> 2. 国内的镜像网站：网易蜂巢、daoCloud。。。
>    https://c.163yun.com/hub#/home
>    https://hub.daocloud.io/ (推荐使用)
> 3. 在公司内部会采用私服的方式拉取镜像。(添加配置)

```json
# 需要在/etc/docker/daemon.json
{
	"registry-mirrors": ["https://registry.docker-cn.com"],
	"insecure-registries": ["ip:port]
}
# ip:port
公司私服的ip和port
# 重启两个服务
systemctl daemon-reload
systemctl restart docker                          
```

##### 2.4 镜像的操作

```sh
# 1. 拉取镜像到本地
docker pull 镜像名称[:tag]
# 举个例子 tomcat
docker pull daocloud.io/library/tomcat:8.5.15-jre8
```

------

```sh
# 2. 查看全部本地的镜像
docker images
```

------

```sh
# 3. 删除本地镜像
docker rmi 镜像的标识
```

------

```sh
# 4. 镜像的导入导出(不规范)
# 将本地的镜像导出
docker save -o 导出的路径 镜像id
# 加载本地的镜像文件
docker load -i 镜像文件
# 修改镜像名称
docker tag 镜像id 新镜像名称:版本
```

##### 2.5 容器的操作

```sh
# 1. 运行容器
# 简单操作
docker run 镜像的标识|镜像名称[tag]
# 常用的参数
docker run -d -p  宿主机端口:容器端口 --name 容器名称 镜像的标识|镜像名称[tag]
# -d: 代表后台运行容器
# -p: 宿主机端口:容器端口: 为了映射当前Linux的端口和容器的端口
# --name 容器名称: 指定容器的名称
```

------

```sh
# 2. 查看正在运行的容器
docker ps [OPTIONS]
# OPTIONS说明:
# -a: 代表查看全部的容器，包括没有运行
# -q: 只查看容器的标识
# -f: 根据条件过滤显示的内容
# --format: 指定返回值的模板文件
# -l: 显示最近创建的容器
# -n: 列出最近创建的n个容器
# --no-trunc: 不截断输出
# -s: 显示总的文件大小
```

------

```sh
# 3. 查看容器的日志
docker logs -f 容器id
# -f: 可以滚动查看日志的最后几行
```

------

```sh
# 4. 进入到容器内部
docker exec -it 容器id bash
```

------

```sh
# 5. 删除容器(删除容器前，需要先停止容器)
docker stop 容器id
# 停止指定的容器
docker stop $(docker ps -qa)
# 停止全部容器
docker rm 镜像id
# 删除指定容器
docker rm $(docker ps -qa)
# 删除全部容器
```

------

```sh
#6. 启动容器
docker start 容器id
```

##### 三.Docker应用

##### 3.1 准备SSM工程

```sh
# MySQL数据库的连接用户名和密码改变了，修改db.propreties
# 项目重新打包
mvn clean package -DskipTests
# 项目地址
链接: https://pan.baidu.com/s/1F4xTLoOFCMb7rl1VUrBASA  密码: bgjw
```

##### 3.2 准备MySQL容器

```sh
# 运行MySQL容器
docker run -d -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=root daocloud.io/library/mysql:5.7.4
```

##### 3.3 准备Tomcat容器

```sh
# 运行Tomcat容器，在上面容器操作中已经搞定，只需要将SSM项目的war包部署到Tomcat容器内部
# 可以通过命令将宿主机的内容复制到容器内部
docker cp 文件名称 容器id:容器内部路径
# 举个例子
docker cp ssm.war fe:/usr/local/tomcat/webapps/
```

##### 3.4数据卷

> 为了部署SSM的工程，需要使用到cp的命令将宿主机内的ssm.war文件复制到容器内部。
>
> 数据卷：将宿主机的一个目录映射到容器的一个目录中。
>
> 可以在宿主机中操作目录中的内容，那么容器内部映射的文件，也会跟着一起改变。

```sh
# 1. 创建数据卷
docker volume create 数据卷名称
# 创建数据卷之后默认会存放在一个目录下 /var/lib/docker/volumes/数据卷名称/_data
```

------

```sh
# 2. 查看数据卷的详细信息
docker volume inspect 数据卷名称
```

------

```sh
# 3. 查看全部数据卷
docker volume ls
```

------

```sh
# 4. 删除数据卷
docker volume rm 数据卷名称
```

------

```sh
# 5. 应用数据卷
# 当你映射数据卷时，如果数据卷不存在。Docker会帮你自动创建
docker run -v 数据卷名称:容器内部路径 镜像id
# 直接指定一个路径作为数据卷的存放位置。这个路径下是空的。
docker run -v 路径:容器内部的路径 镜像id
```

##### 四.Docker自定义镜像

> 中央仓库上的镜像，也是Docker的用户自己上传过去的。

```sh
# 1. 创建一个Dockerfile文件，并且指定自定义镜像信息。
# Dockerfile文件中常用的内容
from: 指定当前自定义镜像依赖的环境
copy: 将相对路径下的内容复制到自定义镜像中
workdir: 声明镜像的默认工作目录
cmd: 需要执行的命令(在workdir下执行的，cmd可以写多个，只以最后一个为准)
# 举个例子，自定义一个tomcat镜像，并且将ssm.war部署到tomcat中
from daocloud.io/library/tomcat:8.5.15-jre8
copy ssm.war /usr/local/tomcat/webapps
```

------

```sh
# 2. 将准备好的Dockerfile和相应的文件拖拽到Linux操作系统中，通过Docker的命令制作镜像
docker build -t 镜像名称:[tag] .
```

##### 五.Docker-Compose

> 之前运行一个镜像，需要添加大量的参数。
>
> 可以通过Docker-Compose编写这些参数。
>
> Docker-Compose可以帮助我们批量的管理容器。
>
> 只需要通过一个docker-compose.yml文件去维护即可。

##### 5.1 下载Docker-Compose

```sh
# 1. 去Github官网搜索docker-compose，下载1.24.1版本的Docker-Compose
https://github.com/docker/compose/releases/download/1.24.1/docker-compose-Linux-x86_64

# 2. 将下载好的文件拖拽到Linux系统中
将文件上传到你所使用的服务器或者虚拟机，然后将文件移动到/usr/local

# 3. 需要将Docker-Compose文件的名称修改一下，基于Docker-Compose文件一个可执行的权限
mv docker-compose-Linux-x86_64 docker-compose
chmod 777 docker-compose

# 4. 方便后期操作，配置一个环境变量
# 将docker-compose文件移动到了/usr/local/bin，修改了/etc/profile文件，给/usr/local/bin配置到了PATH中
mv docker-compose /usr/local/bin
vi /etc/profile
	export PATH=/usr/local/bin:$PATH
source /etc/profile

# 5. 测试一下
# 在任意目录下输入docker-compose
```

![测试结果](https://img-blog.csdnimg.cn/img_convert/b6e4b1a31be51f5269ddda3ac195dbe8.png)

##### 5.2 Docker-Compose管理MySQL和Tomcat容器

> yml文件以key:value方式来指定配置信息
>
> 多个配置信息以换行+缩进的方式来区分
>
> 在docker-compose.yml文件中，不要使用制表符

```yml
version: '3.1'
services:
  mysql:                     # 服务的名称
    restart: always          # 代表只要Docker启动，那么这个容器就跟着一起启动
    image: daocloud.io/library/mysql:5.7.4     # 指定镜像路径
    container_name: mysql    # 指定容器名称
    ports:
      - 3306:3306        # 指定端口号的映射
    environment:
      MYSQL_ROOT_PASSWORD: root         # 指定MySQL的ROOT用户登录密码
      TZ: Asia/Shanghai                 # 指定时区
    volumes:
      - /opt/docker_mysql_tomcat/mysql_data:/var/lib/mysql        # 映射数据卷
  tomcat:
    restart: always          # 代表只要Docker启动，那么这个容器就跟着一起启动
    image: daocloud.io/library/tomcat:8.5.15-jre8     # 指定镜像路径
    container_name: tomcat    # 指定容器名称
    ports:
      - 8080:8080        # 指定端口号的映射
    environment:
      MYSQL_ROOT_PASSWORD: root         # 指定MySQL的ROOT用户登录密码
      TZ: Asia/Shanghai                 # 指定时区
    volumes:
      - /opt/docker_mysql_tomcat/tomcat_webapps:/usr/local/tomcat/webapps        # 映射数据卷
      - /opt/docker_mysql_tomcat/tomcat_logs:/usr/local/tomcat/logs        # 映射数据卷
```

##### 5.3 使用docker-compose命令管理容器

> 在使用docker-compose的命令时，默认会在当前目录下找docker-compose.yml

```sh
# 1. 基于docker-compose.yml启动管理的容器
docker-compose up -d
```

------

```sh
# 2. 关闭并删除容器
docker-compose down
```

------

```sh
# 3. 开启 | 关闭 | 重启已经存在的由docker-compose维护的容器
docker-compose start | stop | restart
```

------

```sh
# 4. 查看由docker-compose管理的容器
docker-compose p
```

------

```sh
# 5. 查看日志
docker-compose logs -f
```

##### 5.4 docker-compose配置Dockerfile使用

> 使用docker-compose.yml文件以及Dockerfile文件在生产自定义镜像的同时启动当前镜像，并且由docker-compose去管理容器

[docker-compose.yml](https://blog.csdn.net/lqpf199681/article/details/110518692?ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522160827066716780261944216%252522%25252C%252522scm%252522%25253A%25252220140713.130102334..%252522%25257D&request_id=160827066716780261944216&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-110518692.nonecase&utm_term=Docker)

```yml
# yml文件
version: '3.1'
services:
  ssm:
    restart: always
    build:          # 构建自定义镜像
      context: ../. # 指定dockerfile文件的所在路径
      dockerfile: Dockerfile  # 指定Dockerfile文件名称
    image: ssm:1.0.1
    container_name: ssm
    ports:
      - 8081:8080
    environment:
      TZ: Asia/Shanghai
```

------

[Dockerfile文件](https://blog.csdn.net/lqpf199681/article/details/110518692?ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522160827066716780261944216%252522%25252C%252522scm%252522%25253A%25252220140713.130102334..%252522%25257D&request_id=160827066716780261944216&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-110518692.nonecase&utm_term=Docker)

```sh
from daocloud.io/library/tomcat:8.5.15-jre8
copy ssm.war /usr/local/tomcat/webapps
```

------

```sh
# 可以直接启动基于docker-compose.yml以及Dockerfile文件构建的自定义镜像
dockr-compose up -d
# 如果自定义镜像不存在，会帮助我们构建出自定义镜像，如果自定义镜像已经存在，会直接运行这个自定义镜像
# 重新构建的话
# 重新构建自定义镜像
docker-compose build
# 运行前，重新构建
docker-compose up -d --build
```

##### 六.Docker DI、CD

##### 6.1 引言

> 项目部署
>
> 1. 将项目通过maven进行编译打包
> 2. 将文件上传到指定的服务器中
> 3. 将war包放到tomcat的目录中
> 4. 通过Dockerfile将Tomcat和war包转成一个镜像，由DockerCompose去运行容器
>
> 项目更新了
>
>  将上述流程再次的从头到尾的执行一次

##### 6.2 CI介绍

> CI(continuous intergration)持续集成
>
> 持续集成：编写代码时，完成了一个功能后，立即提交代码到Git仓库中，将项目重新的构建并进行测试。
>
> - 快递发现错误。
> - 防止代码偏离主分支。

##### 6.3 实现持续集成

##### 6.3.1 搭建Gitlab服务器

> 1、创建一个全新的虚拟机，并且至少指定4G的运行内存

> 2、安装docker以及docker-compose

> 3、将ssh的默认22端口，修改为60022端口

```sh
vi /etc/ssh/sshd_config
Port 22 -> 60022
systemctl restart sshd
```

> 4、docker-compose.yml文件去安装Gitlab(下载和运行的时间比较长)

```yml
version: '3.1'
services:
  gitlab:
    image: 'twang2218/gitlab-ce-zh:11.1.4'
    container_name: 'gitlab'
    restart: always
    privileged: true
    hostname: 'gitlab'
    environment:
      TZ: 'Asia/Shanghai'
      GITLAB_OMNIBUS_CONFIG: |
        external_url 'http://192.168.199.110'
        gitlab_rails['time_zone'] = 'Asia/Shanghai'
        gitlab_rails['smtp_enable'] = true
        gitlab_rails['gitlab_shell_ssh_port'] = 22
    ports:
      - '80:80'
      - '443:443'
      - '22:22'
    volumes:
      - /opt/docker_gitlab/config:/etc/gitlab
      - /opt/docker_gitlab/data:/var/opt/gitlab
      - /opt/docker_gitlab/logs:/var/log/gitlab
```

##### 6.3.2 搭建Gitlab-Runner

> 查看资料中的g i t la b-runner文件即可安装

------

##### 6.3.3 整合项目入门测试

> 1、创建一个maven工程，添加web.xml文件，编写html页面

> 2、编写gitlab-ci.yml文件

```
stages:
  - test

test:
  stage: test
  script:
    - echo first test ci # 输入的命令
```

> 3、将maven工程推送到gitlab中

> 4、可以在gitlab中查看到gitlab-ci.yml编写的内容

```
打开gitlab控制台-左侧CI/CD-流水线-已通过
```

![查看](https://img-blog.csdnimg.cn/img_convert/e7328d8de89f3084209ef9bbef77ac5a.png)

------

##### 6.3.4编写.gitlab-ci.yml文件

> 1、编写.gitlab-ci.yml测试命令使用

```yml
stages:
  - test

test:
  stage: test
  script:
    - echo first test ci
    - /usr/local/maven/apache-maven-3.6.3/bin/mvn package
```

> 2、编写关于dockerfile以及dock er-compose.yml文件的具体内容

```sh
# 1. Dockerfile
FROM daocloud.io/library/tomcat:8.5.15-jre8
COPY testci.war /usr/local/tomcat/webapps
```

------

```sh
# 2. docker-compose.yml
version: '3.1'
services:
  testci:
    build: docker
    restart: always
    container_name: testci
    ports:
    - 8080:8080
```

------

```sh
# 3. ci.yml
stages:
  - test

test:
  stage: test
  script:
    - echo first test ci
    - /usr/local/maven/apache-maven-3.6.3/bin/mvn package
    - cp target/testci-1.0-SNAPSHOT.war docker/testci.war
    - docker-compose down
    - docker-compose up -d --build
    - docker rmi $(docker images -qf dangling=true)
```

> 3、测试

![测试图](https://img-blog.csdnimg.cn/img_convert/1f970fad891bbf11c0675b5bde29a1f8.png)

##### 6.4 CD介绍

> CD（持续交付，持续部署）

##### 6.5 实现持续交付持续部署

##### 6.5.1 安装Jenkins

> 官网：https://www.jenkins.io/

```yml
version: '3.1'
services:
  jeckins:
    image: jenkins/jenkins
    restart: always
    container_name: jenkins
    ports:
      - 8888:8080
      - 50000:50000
    volumes:
      - ./data:/var/jenkins_home
```

> 第一次运行时，会因为data目录没有权限，导致启动失败

```
chmod 777 data
```

> 访问http://192.168.199.109:8888

```
访问速度奇慢无比。。。。
```

> 输入密码

![输入密码](https://img-blog.csdnimg.cn/img_convert/50d151bb40d187bfca7361df00caefd6.png)

> 手动指定插件安装：指定下面两个插件即可
>
> Publish ssh
>
> git param…

这里安装过程忘了截图了。。。因为服务器安装的太快，没反应过来

> 安装成功后，需要指定用户名和密码

![jenkins控制台](https://img-blog.csdnimg.cn/img_convert/0569a30976767303c909bdcf8d4c05fe.png)

------

##### 6.5.2 配置目标服务器以及Gitlab免密码登录

> Gitlab -> Jenkins -> 目标服务器

> 1、Jenkins去连接目标服务器

> 左侧的系统设置

![image-20201202103359125](https://img-blog.csdnimg.cn/img_convert/832c09e7741c628004a42a00856b2c9b.png)

> 选中系统设置

![image-20201202135154813](https://img-blog.csdnimg.cn/img_convert/57e17ad2fbf2a0c2a69adfe8f016ac96.png)

> 搜索Publish over SSH

![image-20201202135435348](https://img-blog.csdnimg.cn/img_convert/6c1860c62976a40963ff40a0532087ee.png)

> 点击新增

![image-20201202150053909](https://img-blog.csdnimg.cn/img_convert/a3ea72cb8050d2158513534bd9d0ff9c.png)

------

##### 6.5.3 配置Gitlab免密码登录

> 1、登录Jenkins容器内部

```
docker exec -it jenkins bash
```

> 2、输入生成SSH密钥命令

```
ssh-keygen -t rsa -C "邮箱"
```

> 3、将密钥复制到Gitlab的SSH中

![image-20201202151117361](https://img-blog.csdnimg.cn/img_convert/4544b08b84c5a09b560549e11485adbd.png)

------

##### 6.5.4 配置JDK和Maven

> 1、复制本地的jdk和maven的压缩包到data目录下

> 2、手动解压

![image-20201202152610797](https://img-blog.csdnimg.cn/img_convert/bc619ae29583dbba18e173717f1f081f.png)

> 3、在监控界面中配置JDK和Maven

![image-20201202152453378](https://img-blog.csdnimg.cn/img_convert/e941a6829ca5a008f79a0396906bbbda.png)

------

##### 6.5.5 手动拉取gitlab项目

> 使用SSH无密码连接时，第一次连接需要手动确定

![image-20201202153041926](https://img-blog.csdnimg.cn/img_convert/f85405393acc6f89f84dd98b86af3f8c.png)

------

##### 6.5.6 创建maven任务

> 1、创建maven工程，推送到gitlab

> 2、jenkins的监控页面中创建maven任务

![image-20201202161727559](https://img-blog.csdnimg.cn/img_convert/a7e2c48e542e6ebdb46d092617ac1ab2.png)

![image-20201202161756699](https://img-blog.csdnimg.cn/img_convert/eac1133874e9ee8bd7d591188d9b20d7.png)

> 3、执行maven任务

![image-20201202162242988](https://img-blog.csdnimg.cn/img_convert/9afd33fdcbc2b80d862fa7e03883d2aa.png)

![image-20201202162104630](https://img-blog.csdnimg.cn/img_convert/f7d470cdc6aee5fb8867f3cf31e611d0.png)

> 4、最终效果

![image-20201202165449820](https://img-blog.csdnimg.cn/img_convert/deaef3b93b9ae40c23e374b43fc27c51.png)

##### 6.6 实现持续交付持续部署

> 1、安装Git Parameter的插件，Persistent Parameter的插件（版本）

![image-20201202165935326](https://img-blog.csdnimg.cn/img_convert/22deb5f69bac7ab0a8d23bbd8759b957.png)

> 2、重新制定构建项目的方式

[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-JmlV9ILd-1606958453454)(/Users/liufei/Library/Application Support/typora-user-images/image-20201202224449925.png)]

------

![image-20201203000655114](https://img-blog.csdnimg.cn/img_convert/dde373a08b9a86fd5ed11c7395f1c8dd.png)

> 3、构建项目成功后，需要将内容发布到目标服务器

![image-20201203000749347](https://img-blog.csdnimg.cn/img_convert/1e7cbbb702eb1fe31602d59eec0482a2.png)

> 4、修改程序代码，（提交到GitLab仓库中）

```
FROM daocloud.io/library/tomcat:8.5.15-jre8
COPY testcd-1.0-SNAPSHOT.war /usr/local/tomcat/webapps
```

------

```
version: '3.1'
services:
  testcd:
    build: docker
    restart: always
    container_name: testcd
    ports:
      - 8081:8080
```

> 5、测试
>
> 1. 给当前代码添加一个标签
> 2. 到Jenkins中查看

![image-20201203001600023](https://img-blog.csdnimg.cn/img_convert/8d58e2769405c6960726610769681299.png)

> 1. 点击上图的开始构建(查看日志)
> 2. 去指定的目标服务器中访问具体服务

#### 多线程：

##### 1. 并行和并发有什么区别？

1. 并行（Parallel）：指两个或者多个事件在同一时刻发生，即同时做不同事的能力。例如垃圾回收时，多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。
2. 并发（Concurrent）：指两个或多个事件在同一时间间隔内发生，即交替做不同事的能力，多线程是并发的一种形式。例如垃圾回收时，用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上。

##### 2. 线程和进程的基本概念、线程的基本状态以及状态之间的关系？

1. 一个线程是进程的一个顺序执行流程。一个进程中的全部线程共享同一个堆空间。线程本身有一个供程序执行时的栈，一个进程中可以包含多个线程。
2. 线程的**基本状态**：新建、就绪、运行状态、阻塞状态、死亡状态
3. 新建状态：利用NEW运算创建了线程对象，此时线程状态为新建状态，调用了新建状态线程的start()方法，将线程提交给操作系统，准备执行，线程将进入到就绪状态。
4. 就绪状态：由操作系统调度的一个线程，没有被系统分配到处理器上执行，一旦处理器有空闲，操作系统会将它放入处理器中执行，此时线程从就绪状态切换到运行时状态。
5. 运行状态：线程正在运行的过程中，碰到调用Sleep()方法，或者等待IO完成，或等待其他同步方法完成时，线程将会从运行状态，进入到阻塞状态。
6. 死亡状态：线程一旦脱离阻塞状态时，将重新回到就绪状态，重新向下执行，最终进入到死亡状态。一旦线程对象是死亡状态，就只能被GC回收，不能再被调用。

##### 3. 守护线程是什么？

1. 守护线程又称为后台线程，它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件
2. 正常创建的线程都是普通线程，或称为前台线程，守护线程与普通线程在使用上没有什么区别，但是他们有一个最主要的区别是在于进程的结束中。当一个进程中所有普通线程都结束时，那么进程就会结束。如果进程结束时还有守护线程在运行，那么这些守护线程就会被强制结束
3. 在 Java 中垃圾回收线程就是特殊的守护线程

##### 4. 创建线程有哪几种方式？

1. 继承Thread类（真正意义上的线程类），是Runnable接口的实现。
2. 实现Runnable接口，并重写里面的run方法。
3. 使用Executor框架创建线程池。Executor框架是juc里提供的线程池的实现。

##### 5. sleep() 和 wait() 有什么区别？

1. 类的不同：sleep() 来自 Thread，wait() 来自 Object。
2. 释放锁：sleep() 不释放锁；wait() 释放锁。
3. 用法不同：sleep() 时间到会自动恢复；wait() 可以使用 notify()/notifyAll()直接唤醒。

##### 6. 线程的 run() 和 start() 有什么区别？

1. start() 方法用于启动线程，run() 方法用于执行线程的运行时代码。
2. run() 可以重复调用，而 start() 只能调用一次。
3. 第二次调用start() 必然会抛出运行时异常

##### 7. 创建线程池有哪几种方式？

1. newSingleThreadExecutor()：它的特点在于工作线程数目被限制为 1，操作一个无界的工作队列，所以它保证了所有任务的都是被顺序执行，最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可以避免其改变线程数目；
2. newCachedThreadPool()：它是一种用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置的时间超过 60 秒，则被终止并移出缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用 SynchronousQueue 作为工作队列；
3. newFixedThreadPool(int nThreads)：重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列，任何时候最多有 nThreads 个工作线程是活动的。这意味着，如果任务数量超过了活动队列数目，将在工作队列中等待空闲线程出现；如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目 nThreads；
4. newSingleThreadScheduledExecutor()：创建单线程池，返回 ScheduledExecutorService，可以进行定时或周期性的工作调度；
5. newScheduledThreadPool(int corePoolSize)：和newSingleThreadScheduledExecutor()类似，创建的是个 ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程；
6. newWorkStealingPool(int parallelism)：这是一个经常被人忽略的线程池，Java 8 才加入这个创建方法，其内部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序；
7. ThreadPoolExecutor()：是最原始的线程池创建，上面1-3创建方式都是对ThreadPoolExecutor的封装。

##### 8. 在 Java 程序中怎么保证多线程的运行安全？

1. 使用安全类，比如 Java. util. concurrent 下的类。
2. 使用自动锁 synchronized。
3. 使用手动锁 Lock。

1.Vector

Vector和ArrayList类似，是长度可变的数组，与ArrayList不同的是，Vector是线程安全的，它给几乎所有的public方法都加上了synchronized关键字。由于加锁导致性能降低，在不需要并发访问同一对象时，这种强制性的同步机制就显得多余，所以现在Vector已被弃用

2.HashTable

HashTable和HashMap类似，不同点是HashTable是线程安全的，它给几乎所有public方法都加上了synchronized关键字，还有一个不同点是HashTable的K，V都不能是null，但HashMap可以，它现在也因为性能原因被弃用了

二、Collections包装方法

Vector和HashTable被弃用后，它们被ArrayList和HashMap代替，但它们不是线程安全的，所以Collections工具类中提供了相应的包装方法把它们包装成线程安全的集合

```
List<E> synArrayList = Collections.synchronizedList(new ArrayList<E>());

Set<E> synHashSet = Collections.synchronizedSet(new HashSet<E>());

Map<K,V> synHashMap = Collections.synchronizedMap(new HashMap<K,V>());

...1234567
```

Collections针对每种集合都声明了一个线程安全的包装类，在原集合的基础上添加了锁对象，集合中的每个方法都通过这个锁对象实现同步

三、java.util.concurrent包中的集合

1.ConcurrentHashMap

ConcurrentHashMap和HashTable都是线程安全的集合，它们的不同主要是加锁粒度上的不同。HashTable的加锁方法是给每个方法加上synchronized关键字，这样锁住的是整个Table对象。而ConcurrentHashMap是更细粒度的加锁 
在JDK1.8之前，ConcurrentHashMap加的是分段锁，也就是Segment锁，每个Segment含有整个table的一部分，这样不同分段之间的并发操作就互不影响 
JDK1.8对此做了进一步的改进，它取消了Segment字段，直接在table元素上加锁(乐观锁CAS算法)，实现对每一行进行加锁，进一步减小了并发冲突的概率

2.CopyOnWriteArrayList和CopyOnWriteArraySet

它们是加了写锁的ArrayList和ArraySet，锁住的是整个对象，但读操作可以并发执行

除此之外还有ConcurrentSkipListMap、ConcurrentSkipListSet、ConcurrentLinkedQueue、ConcurrentLinkedDeque等，至于为什么没有ConcurrentArrayList，原因是无法设计一个通用的而且可以规避ArrayList的并发瓶颈的线程安全的集合类，只能锁住整个list，这用Collections里的包装类就能办到

##### 9. 什么是死锁？怎么防止死锁？

1. 当线程 A 持有独占锁a，并尝试去获取独占锁 b 的同时，线程 B 持有独占锁 b，并尝试获取独占锁 a 的情况下，就会发生 AB 两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。
2. 防止死锁方法：
   1. 尽量使用 tryLock(long timeout, TimeUnit unit)的方法(ReentrantLock、ReentrantReadWriteLock)，设置超时时间，超时可以退出防止死锁。
   2. 尽量使用 Java. util. concurrent 并发类代替自己手写锁。
   3. 尽量降低锁的使用粒度，尽量不要几个功能用同一把锁。
   4. 尽量减少同步的代码块。

##### 10. synchronized 和 volatile 的区别是什么？

1. volatile 是变量修饰符；synchronized 是修饰类、方法、代码段。
2. volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子性。
3. volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。

##### 11. synchronized 和 Lock 有什么区别？

1. synchronized 可以给类、方法、代码块加锁；而 lock 只能给代码块加锁。
2. synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；而 lock 需要自己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。
3. 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。

##### 12. synchronized 和 ReentrantLock 区别是什么？

1. ReentrantLock 使用起来比较灵活，但是必须有释放锁的配合动作；
2. ReentrantLock 必须手动获取与释放锁，而 synchronized 不需要手动释放和开启锁；
3. ReentrantLock 只适用于代码块锁，而 synchronized 可用于修饰方法、代码块等。

##### 13. 为什么使用线程池？

由于创建和销毁线程都需要很大的开销，运用线程池就可以大大的缓解这些内存开销很大的问题；可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存。

#### [JVM：](https://blog.csdn.net/xiaofeng10330111/article/details/105360974?ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522160825063116780265356822%252522%25252C%252522scm%252522%25253A%25252220140713.130102334..%252522%25257D&request_id=160825063116780265356822&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-105360974.nonecase&utm_term=jvm)

JDK8 之前的内存区域图如下:

![img](https://img-blog.csdnimg.cn/2020041119404981.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9mZW5nMTAzMzAxMTE=,size_16,color_FFFFFF,t_70)

JDK8 之后的内存区域图如下:

![img](https://img-blog.csdnimg.cn/20200411194152415.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9mZW5nMTAzMzAxMTE=,size_16,color_FFFFFF,t_70)

Java 8 中 PermGen 为什么被移出 HotSpot JVM 了？两个主要原因:

1. 由于 PermGen 内存经常会溢出，引发恼人的 *java.lang.OutOfMemoryError: PermGen*，因此 JVM 的开发者希望这一块内存可以更灵活地被管理，不要再经常出现这样的 OOM
2. 移除 PermGen 可以促进 HotSpot JVM 与 JRockit VM 的融合，因为 JRockit 没有永久代。
   根据上面的各种原因，PermGen 最终被移除，**方法区移至 Metaspace，字符串常量移至 Java Heap**。

##### 运行时数据区：

| 序号 | 区域名称     | 共享     | 作用                                                         | 异常                                                         | 备注                                                         |
| ---- | ------------ | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | 程序计数器   | 线程私有 | 记录当前线程所执行的字节码行号指示器。                       | Java虚拟机规范中唯一一个没有规定OutOfMemoryError(内存不足错误)的区域。 | --                                                           |
| 2    | Java虚拟机栈 | 线程私有 | 存放局部变量表、操作数据栈、动态链接、方法出口等信息。       | 栈深大于允许的最大深度，抛出StackOverflowError(栈溢出错误)。 内存不足时，抛出OutOfMemoryError(内存不足错误)。 | 常说的“栈”说的就是Java虚拟机栈，或者是Java虚拟机栈中的局部变量表。 |
| 3    | 本地方法栈   | 线程私有 | 和Java虚拟机栈类似，不过是为JVM用到的Native方法服务。        | 同上                                                         | --                                                           |
| 4    | Java堆       | 线程共享 | 存放实例化数据。                                             | 内存不足时，抛出OutOfMemoryError(内存不足错误)。             | 通过-Xmx和-Xms控制大小。 GC的主要管理对象。                  |
| 5    | 方法区       | 线程共享 | 存放类信息（版本、字段、方法、接口等）、常量、静态变量、即时编译后的代码等数据。 | 内存不足时，抛出OutOfMemoryError(内存不足错误)。             | --                                                           |
| 6    | 运行时常量池 | 线程共享 | 存放编译期生成的各种字面量和符号引用。                       | 内存不足时，抛出OutOfMemoryError(内存不足错误)。             | 属于“方法区”的一部分。                                       |
| 7    | 直接内存     | --       | 如NIO可以使用Native函数库直接分配堆外内存，该内存受计算机内存限制。 | 内存不足时，抛出OutOfMemoryError(内存不足错误)。             | 不是JVM运行时数据区的一部分，也不是JVM虚拟机规范中定义的内存区域。但这部分内存也被频繁的使用。所以放到一起。 |

JVM运行时会分配好方法区和堆，而JVM每遇到一个线程，就为其分配一个程序计数器、Java栈、本地方法栈，当线程终止时，三者（程序计数器、Java栈、本地方法栈）所占用的内存空间也会释放掉。

程序计数器、Java栈、本地方法栈的生命周期与所属线程相同，而方法区和堆的生命周期与JAVA程序运行生命周期相同，所以gc只发生在线程共享的区域（大部分发生在Heap上）。

1、方法区：

有时候也称为永久代（Permanent Generation），在方法区中，存储了每个类的信息（包括类的名称、修饰符、方法信息、字段信息）、类中静态变量、类中定义为final类型的常量、类中的Field信息、类中的方法信息以及编译器编译后的代码等。当开发人员在程序中通过Class对象中的getName、isInterface等方法来获取信息时，这些数据都来源于方法区域，同时方法区域也是全局共享的，在一定的条件下它也会被GC，在这里进行的GC主要是方法区里的常量池和类型的卸载。当方法区域需要使用的内存超过其允许的大小时，会抛出OutOfMemory的错误信息。

在方法区中有一个非常重要的部分就是运行时常量池，用于存放静态编译产生的字面量和符号引用。运行时生成的常量也会存在这个常量池中，比如String的intern方法。它是每一个类或接口的常量池的运行时表示形式，在类和接口被加载到JVM后，对应的运行时常量池就被创建出来。

2、堆：

Java中的堆是用来存储对象实例以及数组（当然，数组引用是存放在Java栈中的）。堆是被所有线程共享的，因此在其上进行对象内存的分配均需要进行加锁，这也导致了new对象的开销是比较大的。在JVM中只有一个堆。堆是Java垃圾收集器管理的主要区域，Java的垃圾回收机制会自动进行处理。

Sun Hotspot JVM为了提升对象内存分配的效率，对于所创建的线程都会分配一块独立的空间TLAB（Thread Local Allocation Buffer），其大小由JVM根据运行的情况计算而得，在TLAB上分配对象时不需要加锁，因此JVM在给线程的对象分配内存时会尽量的在TLAB上分配，在这种情况下JVM中分配对象内存的性能和C基本是一样高效的，但如果对象过大的话则仍然是直接使用堆空间分配。

堆空间分为老年代和年轻代。刚创建的对象存放在年轻代，而老年代中存放生命周期长久的实例对象。年轻代中又被分为Eden区和两个Survivor区(From Space和To Space)。新的对象分配是首先放在Eden区，Survivor区作为Eden区和Old区的缓冲，在Survivor区的对象经历若干次GC仍然存活的，就会被转移到老年代。 当一个对象大于eden区而小于old区（老年代）的时候会直接扔到old区。 而当对象大于old区时，会直接抛出OutOfMemoryError（OOM）。

3、Java栈：

Java栈也称作虚拟机栈（Java Vitual Machine Stack），也就是我们常常所说的栈。JVM栈是线程私有的，每个线程创建的同时都会创建自己的JVM栈，互不干扰。

![img](https://img-blog.csdnimg.cn/20200411194730271.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9mZW5nMTAzMzAxMTE=,size_16,color_FFFFFF,t_70)

Java栈是Java方法执行的内存模型。Java栈中存放的是一个个的栈帧，每个栈帧对应一个被调用的方法，在栈帧中包括局部变量表(Local Variables)、操作数栈(Operand Stack)、指向当前方法所属的类的运行时常量池的引用(Reference to runtime constant pool)、方法返回地址(Return Address)和一些额外的附加信息。当线程执行一个方法时，就会随之创建一个对应的栈帧，并将建立的栈帧压栈。当方法执行完毕之后，便会将栈帧出栈。因此可知，线程当前执行的方法所对应的栈帧必定位于Java栈的顶部。

局部变量表：用来存储方法中的局部变量（包括在方法中声明的非静态变量以及函数形参）。对于基本数据类型的变量，则直接存储它的值，对于引用类型的变量，则存的是指向对象的引用。局部变量表的大小在编译期就可以确定其大小了，因此在程序执行期间局部变量表的大小是不会改变的。

i++ 和 ++i 的区别：

1. i++：从局部变量表取出 i 并压入操作栈，然后对局部变量表中的 i 自增 1，将操作栈栈顶值取出使用，最后，使用栈顶值更新局部变量表，如此线程从操作栈读到的是自增之前的值。
2. ++i：先对局部变量表的 i 自增 1，然后取出并压入操作栈，再将操作栈栈顶值取出使用，最后，使用栈顶值更新局部变量表，线程从操作栈读到的是自增之后的值。

之前之所以说 i++ 不是原子操作，即使使用 volatile 修饰也不是线程安全，就是因为，可能 i 被从局部变量表（内存）取出，压入操作栈（寄存器），操作栈中自增，使用栈顶值更新局部变量表（寄存器更新写入内存），其中分为 3 步，volatile 保证可见性，保证每次从局部变量表读取的都是最新的值，但可能这 3 步可能被另一个线程的 3 步打断，产生数据互相覆盖问题，从而导致 i 的值比预期的小。

操作数栈：栈最典型的一个应用就是用来对表达式求值。在一个线程执行方法的过程中，实际上就是不断执行语句的过程，而归根到底就是进行计算的过程。因此可以这么说，程序中的所有计算过程都是在借助于操作数栈来完成的。

指向运行时常量池的引用：因为在方法执行的过程中有可能需要用到类中的常量，所以必须要有一个引用指向运行时常量。

方法返回地址：当一个方法执行完毕之后，要返回之前调用它的地方，因此在栈帧中必须保存一个方法返回地址。

4、程序计数器：

程序计数器（Program Counter Register），也有称作为PC寄存器。

由于在JVM中，多线程是通过线程轮流切换来获得CPU执行时间的，因此，在任一具体时刻，一个CPU的内核只会执行一条线程中的指令，因此，为了能够使得每个线程都在线程切换后能够恢复在切换之前的程序执行位置，每个线程都需要有自己独立的程序计数器，并且不能互相被干扰，否则就会影响到程序的正常执行次序。因此，可以这么说，程序计数器是每个线程所私有的。

在JVM规范中规定，如果线程执行的是非native（本地）方法，则程序计数器中保存的是当前需要执行的指令的地址；如果线程执行的是native方法，则程序计数器中的值是undefined。

由于程序计数器中存储的数据所占空间的大小不会随程序的执行而发生改变，因此，对于程序计数器是不会发生内存溢出现象(OutOfMemory)的。

5、本地方法栈：

JVM采用本地方法栈来支持native方法的执行，此区域用于存储每个native方法调用的状态。本地方法栈与Java栈的作用和原理非常相似。区别只不过是Java栈是为执行Java方法服务的，而本地方法栈则是为执行本地方法（Native Method）服务的。在JVM规范中，并没有对本地方法栈的具体实现方法以及数据结构作强制规定，虚拟机可以自由实现它。在HotSopt虚拟机中直接就把本地方法栈和Java栈合二为一。

**JDK8 之前，Hotspot 中方法区的实现是永久代（Perm），JDK8 开始使用元空间（Metaspace），以前永久代所有内容的字符串常量移至堆内存，其他内容移至元空间，元空间直接在本地内存分配。**

为什么要使用元空间取代永久代的实现？

- 字符串存在永久代中，容易出现性能问题和内存溢出。
- 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。
- 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。
- 将 HotSpot 与 JRockit 合二为一。

补充内容：

- 运行时常量池

运行时常量池（Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。

一般来说，除了保存 Class 文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。

运行时常量池相对于 Class 文件常量池的另外一个重要特征是具备动态性，Java 语言并不要求常量一定只有编译期才能产生，也就是并非预置入 Class 文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是 String 类的 intern() 方法。

既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。

- 直接内存

直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域。

在 JDK 1.4 中新加入了 NIO，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。

显然，本机直接内存的分配不会受到 Java 堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括 RAM 以及 SWAP 区或者分页文件）大小以及处理器寻址空间的限制。服务器管理员在配置虚拟机参数时，会根据实际内存设置 -Xmx 等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现 OutOfMemoryError 异常。

##### 类加载机制

Class文件由类装载器装载后，在JVM中将形成一份描述Class结构的元信息对象，通过该元信息对象可以获知Class的结构信息：如构造函数，属性和方法等，Java允许用户借由这个Class相关的元信息对象间接调用Class对象的功能。

虚拟机把描述类的数据从class文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。

![1608273106769](D:\AppData\Roaming\Typora\typora-user-images\1608273106769.png)

##### 垃圾回收机制



##### 内存溢出

内存泄漏memory leak :是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄漏似乎不会有大的影响，但内存泄漏堆积后的后果就是内存溢出。 

内存溢出 out of memory :指程序申请内存时，没有足够的内存供申请者使用，或者说，给了你一块存储int类型数据的存储空间，但是你却存储long类型的数据，那么结果就是内存不够用，此时就会报错OOM,即所谓的内存溢出。 

内存溢出原因： 

1.内存中加载的数据量过于庞大，如一次从数据库取出过多数据； 

2.集合类中有对对象的引用，使用完后未清空，使得JVM不能回收； 

3.代码中存在死循环或循环产生过多重复的对象实体；

4.使用的第三方软件中的BUG； 

5.启动参数内存值设定的过小

内存溢出的解决方案： 

第一步，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)

第二步，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。

第三步，对代码进行走查和分析，找出可能发生内存溢出的位置。

##### GC调优

**代大小优化**

最关键参数：-Xms、 -Xmx 、-Xmn 、-XX:SurvivorRatio、-XX:MaxTenuringThreshold、-XX:PermSize、-XX:MaxPermSize

-Xms、 -Xmx 通常设置为相同的值，避免运行时要不断扩展JVM内存，这个值决定了JVM heap所能使用的最大内存。

-Xmn 决定了新生代空间的大小，新生代Eden、S0、S1三个区域的比率可以通过-XX:SurvivorRatio来控制(假如值为 4  表示：Eden:S0:S1 = 4:3:3 )

-XX:MaxTenuringThreshold 控制对象在经过多少次minor GC之后进入老年代，此参数只有在Serial 串行GC时有效。

-XX:PermSize、-XX:MaxPermSize 用来控制方法区的大小，通常设置为相同的值。

1.避免新生代大小设置过小

当新生代设置过小时，会产生两种比较明显的现象，一是minor GC次数频繁，二是可能导致 minor GC对象直接进入老年代。当老年代内存不足时，会触发Full GC。

2.避免新生代大小设置过大

新生代设置过大，会带来两个问题：一是老年代变小，可能导致Full  GC频繁执行；二是 minor GC 执行回收的时间大幅度增加。

3.避免Survivor区过大或过小

-XX:SurvivorRatio参数的值越大，就意味着Eden区域变大，minor GC次数会降低，但两块Survivor区域变小，如果超过Survivor区域内存大小的对象在minor GC后仍没被回收，则会直接进入老年代，

-XX:SurvivorRatio参数值设置过小，就意味着Eden区域变小，minor GC触发次数会增加，Survivor区域变大，意味着可以存储更多在minor GC后任存活的对象，避免其进入老年代。

4.合理设置对象在新生代存活的周期

新生代存活周期的值决定了新生代对象在经过多少次Minor GC后进入老年代。因此这个值要根据自己的应用来调优，Jvm参数上这个值对应的为-XX:MaxTenuringThreshold，默认值为15次。

**减少GC开销的措施**

　　　　1)不要显式调用System.gc()。此函数建议JVM进行主GC,虽然只是建议而非一定,但很多情况下它会触发主GC,从而增加主GC的频率,也即增加了间歇性停顿的次数。大大的影响系统性能。

　　　  2)尽量减少临时对象的使用。临时对象在跳出函数调用后,会成为垃圾,少用临时变量就相当于减少了垃圾的产生,从而延长了出现上述第二个触发条件出现的时间,减少了主GC的机会。

　　　　3)对象不用时最好显式置为Null。一般而言,为Null的对象都会被作为垃圾处理,所以将不用的对象显式地设为Null,有利于GC收集器判定垃圾,从而提高了GC的效率。

　　　　4)尽量使用StringBuffer,而不用String来累加字符串。由于String是固定长的字符串对象,累加String对象时,并非在一个String对象中扩增,而是重新创建新的String对象,如Str5=Str1+Str2+Str3+Str4,这条语句执行过程中会产生多个垃圾对象,因为对次作“+”操作时都必须创建新的String对象,但这些过渡对象对系统来说是没有实际意义的,只会增加更多的垃圾。避免这种情况可以改用StringBuffer来累加字符串,因StringBuffer是可变长的,它在原有基础上进行扩增,不会产生中间对象。

　　　　5)能用基本类型如Int,Long,就不用Integer,Long对象。基本类型变量占用的内存资源比相应对象占用的少得多,如果没有必要,最好使用基本变量。

　　　　6)尽量少用静态对象变量。静态变量属于全局变量,不会被GC回收,它们会一直占用内存。

　　　　7)分散对象创建或删除的时间。集中在短时间内大量创建新对象,特别是大对象,会导致突然需要大量内存,JVM在面临这种情况时,只能进行主GC,以回收内存或整合内存碎片,从而增加主GC的频率。集中删除对象,道理也是一样的。它使得突然出现了大量的垃圾对象,空闲空间必然减少,从而大大增加了下一次创建新对象时强制主GC的机会。

#### MQ中间件：

|            | ActiveMQ                                                | RabbitMQ                                                     | RocketMQ                                                     | Kafka                                                        | ZeroMQ               |
| ---------- | ------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------- |
| 单机吞吐量 | 比RabbitMQ低                                            | 2.6w/s（消息做持久化）                                       | 11.6w/s                                                      | 17.3w/s                                                      | 29w/s                |
| 开发语言   | Java                                                    | Erlang                                                       | Java                                                         | Scala/Java                                                   | C                    |
| 主要维护者 | Apache                                                  | Mozilla/Spring                                               | Alibaba                                                      | Apache                                                       | iMatix，创始人已去世 |
| 成熟度     | 成熟                                                    | 成熟                                                         | 开源版本不够成熟                                             | 比较成熟                                                     | 只有C、PHP等版本成熟 |
| 订阅形式   | 点对点(p2p)、广播（发布-订阅）                          | 提供了4种：direct, topic ,Headers和fanout。fanout就是广播模式 | 基于topic/messageTag以及按照消息类型、属性进行正则匹配的发布订阅模式 | 基于topic以及按照topic进行正则匹配的发布订阅模式             | 点对点(p2p)          |
| 持久化     | 支持少量堆积                                            | 支持少量堆积                                                 | 支持大量堆积                                                 | 支持大量堆积                                                 | 不支持               |
| 顺序消息   | 不支持                                                  | 不支持                                                       | 支持                                                         | 支持                                                         | 不支持               |
| 性能稳定性 | 好                                                      | 好                                                           | 一般                                                         | 较差                                                         | 很好                 |
| 集群方式   | 支持简单集群模式，比如’主-备’，对高级集群模式支持不好。 | 支持简单集群，'复制’模式，对高级集群模式支持不好。           | 常用 多对’Master-Slave’ 模式，开源版本需手动切换Slave变成Master | 天然的‘Leader-Slave’无状态集群，每台服务器既是Master也是Slave | 不支持               |
| 管理界面   | 一般                                                    | 较好                                                         | 一般                                                         | 无                                                           | 无                   |

##### Kafka

**1.kafka又是什么？**

在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算。

1）Apache Kafka是一个开源消息系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。

2）Kafka最初是由LinkedIn公司开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。

3）Kafka是一个分布式消息队列。Kafka对消息保存时根据Topic进行归类，发送消息者称为Producer，消息接受者称为Consumer，此外kafka集群有多个kafka实例组成，每个实例(server)称为broker。

4）无论是kafka集群，还是consumer都依赖于zookeeper集群保存一些meta信息，来保证系统可用性。

**2.kafka由什么组成？**

一个典型的Kafka体系架构包括若干Producer(可以是服务器日志，业务数据，页面前端产生的page view等等)，若干broker(Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高)，若干Consumer (Group)，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。Producer使用push(推)模式将消息发布到broker，Consumer使用pull(拉)模式从broker订阅并消费消息。

1）Producer ：消息生产者，就是向kafka broker发消息的客户端；

2）Consumer ：消息消费者，向kafka broker取消息的客户端；

3）Topic ：可以理解为一个队列；

4） Consumer Group （CG）：这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个partion只会把消息发给该CG中的一个consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic；

5）Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic；

6）Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序；

7）Offset：kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka。

**3.kafka工作流程分析？**

写入流程：
​      1）producer先从zookeeper的 "/brokers/.../state"节点找到该partition的leader

2）producer将消息发送给该leader

3）leader将消息写入本地log

4）followers从leader pull消息，写入本地log后向leader发送ACK

5）leader收到所有ISR中的replication的ACK后，增加HW（high watermark，最后commit 的offset）并向producer发送ACK

存储策略：

无论消息是否被消费，kafka都会保留所有消息。有两种策略可以删除旧数据：

1）基于时间：log.retention.hours=168

2）基于大小：log.retention.bytes=1073741824

需要注意的是，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。

消费过程：

能够让开发者自己控制offset，想从哪里读取就从哪里读取。

自行控制连接分区，对分区自定义进行负载均衡

对zookeeper的依赖性降低（如：offset不一定非要靠zk存储，自行存储offset即可，比如存在文件或者内存中）

消费者组：

消费者是以consumer group消费者组的方式工作，由一个或者多个消费者组成一个组，共同消费一个topic。每个分区在同一时间只能由group中的一个消费者读取，但是多个group可以同时消费这个partition。在图中，有一个由三个消费者组成的group，有一个消费者读取主题中的两个分区，另外两个分别读取一个分区。某个消费者读取某个分区，也可以叫做某个消费者是某个分区的拥有者。

在这种情况下，消费者可以通过水平扩展的方式同时读取大量的消息。另外，如果一个消费者失败了，那么其他的group成员会自动负载均衡读取之前失败的消费者读取的分区。

消费方式：

consumer采用pull（拉）模式从broker中读取数据。

push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。

对于Kafka而言，pull模式更合适，它可简化broker的设计，consumer可自主控制消费消息的速率，同时consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。

pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直等待数据到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞（并且可选地等待到给定的字节数，以确保大的传输大小）。

#### [Netty](https://thinkwon.blog.csdn.net/article/details/104391081)

Netty是 一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。Netty是基于NIO的，它封装了JDK的NIO，让我们使用起来更加方法灵活。

- 高并发：Netty 是一款基于 NIO（Nonblocking IO，非阻塞IO）开发的网络通信框架，对比于 BIO（Blocking I/O，阻塞IO），他的并发性能得到了很大提高。
- 传输快：Netty 的传输依赖于零拷贝特性，尽量减少不必要的内存拷贝，实现了更高效率的传输。
- 封装好：Netty 封装了 NIO 操作的很多细节，提供了易于使用调用接口。

典型的应用有：阿里分布式服务框架 Dubbo，默认使用 Netty 作为基础通信组件，还有 RocketMQ 也是使用 Netty 作为通讯的基础。

##### Netty 高性能表现在哪些方面？

- IO 线程模型：同步非阻塞，用最少的资源做更多的事。
- 内存零拷贝：尽量减少不必要的内存拷贝，实现了更高效率的传输。
- 内存池设计：申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。
- 串形化处理读写：避免使用锁带来的性能开销。
- 高性能序列化协议：支持 protobuf 等高性能序列化协议。

##### BIO、NIO和AIO的区别？

BIO：一个连接一个线程，客户端有连接请求时服务器端就需要启动一个线程进行处理。线程开销大。
伪异步IO：将请求连接放入线程池，一对多，但线程还是很宝贵的资源。

NIO：一个请求一个线程，但客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。

AIO：一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，

BIO是面向流的，NIO是面向缓冲区的；BIO的各种流是阻塞的。而NIO是非阻塞的；BIO的Stream是单向的，而NIO的channel是双向的。

NIO的特点：事件驱动模型、单线程处理多任务、非阻塞I/O，I/O读写不再阻塞，而是返回0、基于block的传输比基于流的传输更高效、更高级的IO函数zero-copy、IO多路复用大大提高了Java网络应用的可伸缩性和实用性。基于Reactor线程模型。

在Reactor模式中，事件分发器等待某个事件或者可应用或个操作的状态发生，事件分发器就把这个事件传给事先注册的事件处理函数或者回调函数，由后者来做实际的读写操作。如在Reactor中实现读：注册读就绪事件和相应的事件处理器、事件分发器等待事件、事件到来，激活分发器，分发器调用事件对应的处理器、事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。

##### NIO的组成？

Buffer：与Channel进行交互，数据是从Channel读入缓冲区，从缓冲区写入Channel中的

flip方法 ： 反转此缓冲区，将position给limit，然后将position置为0，其实就是切换读写模式

clear方法 ：清除此缓冲区，将position置为0，把capacity的值给limit。

rewind方法 ： 重绕此缓冲区，将position置为0

DirectByteBuffer可减少一次系统空间到用户空间的拷贝。但Buffer创建和销毁的成本更高，不可控，通常会用内存池来提高性能。直接缓冲区主要分配给那些易受基础系统的本机I/O 操作影响的大型、持久的缓冲区。如果数据量比较小的中小应用情况下，可以考虑使用heapBuffer，由JVM进行管理。

Channel：表示 IO 源与目标打开的连接，是双向的，但不能直接访问数据，只能与Buffer 进行交互。通过源码可知，FileChannel的read方法和write方法都导致数据复制了两次！

Selector可使一个单独的线程管理多个Channel，open方法可创建Selector，register方法向多路复用器器注册通道，可以监听的事件类型：读、写、连接、accept。注册事件后会产生一个SelectionKey：它表示SelectableChannel 和Selector 之间的注册关系，wakeup方法：使尚未返回的第一个选择操作立即返回，唤醒的

原因是：注册了新的channel或者事件；channel关闭，取消注册；优先级更高的事件触发（如定时器事件），希望及时处理。

Selector在Linux的实现类是EPollSelectorImpl，委托给EPollArrayWrapper实现，其中三个native方法是对epoll的封装，而EPollSelectorImpl. implRegister方法，通过调用epoll_ctl向epoll实例中注册事件，还将注册的文件描述符(fd)与SelectionKey的对应关系添加到fdToKey中，这个map维护了文件描述符与SelectionKey的映射。

fdToKey有时会变得非常大，因为注册到Selector上的Channel非常多（百万连接）；过期或失效的Channel没有及时关闭。fdToKey总是串行读取的，而读取是在select方法中进行的，该方法是非线程安全的。

Pipe：两个线程之间的单向数据连接，数据会被写到sink通道，从source通道读取

NIO的服务端建立过程：

- Selector.open()：打开一个Selector；

- ServerSocketChannel.open()：创建服务端的Channel；

- bind()：绑定到某个端口上。并配置非阻塞模式；

- register()：注册Channel和关注的事件到Selector上；

- select()轮询拿到已经就绪的事件

##### Netty 和 Tomcat 的区别？

- 作用不同：Tomcat 是 Servlet 容器，可以视为 Web 服务器，而 Netty 是异步事件驱动的网络应用程序框架和工具用于简化网络编程，例如TCP和UDP套接字服务器。
- 协议不同：Tomcat 是基于 http 协议的 Web 服务器，而 Netty 能通过编程自定义各种协议，因为 Netty 本身自己能编码/解码字节流，所有 Netty 可以实现，HTTP 服务器、FTP 服务器、UDP 服务器、RPC 服务器、WebSocket 服务器、Redis 的 Proxy 服务器、MySQL 的 Proxy 服务器等等。

##### TCP 粘包/拆包的原因及解决方法？

TCP是以流的方式来处理数据，一个完整的包可能会被TCP拆分成多个包进行发送，也可能把小的封装成一个大的数据包发送。

TCP粘包/分包的原因：

应用程序写入的字节大小大于套接字发送缓冲区的大小，会发生拆包现象，而应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包现象；

进行MSS大小的TCP分段，当TCP报文长度-TCP头部长度>MSS的时候将发生拆包
以太网帧的payload（净荷）大于MTU（1500字节）进行ip分片。

解决方法

消息定长：FixedLengthFrameDecoder类

包尾增加特殊字符分割：

- 行分隔符类：LineBasedFrameDecoder
- 或自定义分隔符类 ：DelimiterBasedFrameDecoder

将消息分为消息头和消息体：LengthFieldBasedFrameDecoder类。分为有头部的拆包与粘包、长度字段在前且有头部的拆包与粘包、多扩展头部的拆包与粘包。

##### 什么是 Netty 的零拷贝？

Netty 的零拷贝主要包含三个方面：

- Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS，使用堆外直接内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
- Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样方便的对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffer。
- Netty 的文件传输采用了 transferTo 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。

##### Netty 中有哪种重要组件？

- Channel：Netty 网络操作抽象类，它除了包括基本的 I/O 操作，如 bind、connect、read、write 等。
- EventLoop：主要是配合 Channel 处理 I/O 操作，用来处理连接的生命周期中所发生的事情。
- ChannelFuture：Netty 框架中所有的 I/O 操作都为异步的，因此我们需要 ChannelFuture 的 addListener()注册一个 ChannelFutureListener 监听事件，当操作执行成功或者失败时，监听就会自动触发返回结果。
- ChannelHandler：充当了所有处理入站和出站数据的逻辑容器。ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。
- ChannelPipeline：为 ChannelHandler 链提供了容器，当 channel 创建时，就会被自动分配到它专属的 ChannelPipeline，这个关联是永久性的。

##### Netty 发送消息有几种方式？

Netty 有两种发送消息的方式：

- 直接写入 Channel 中，消息从 ChannelPipeline 当中尾部开始移动；
- 写入和 ChannelHandler 绑定的 ChannelHandlerContext 中，消息从 ChannelPipeline 中的下一个 ChannelHandler 中移动。

##### 默认情况 Netty 起多少线程？何时启动？

Netty 默认是 CPU 处理器数的两倍，bind 完之后启动。

#### [分布式事务](https://blog.csdn.net/lizhen1114/article/details/80110317?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control)

![1609728214746](D:\Desktop\文件\拓展\拓展.assets\1609728214746.png)

#### Restful

###### 资源与URI

资源是以json(或其他Representation)为载体的、面向用户的一组数据集，资源对信息的表达倾向于概念模型中的数据：

> 1. 资源总是以某种Representation为载体显示的，即序列化的信息
> 2. 常用的Representation是json或者xml等
> 3. Represntation 是REST架构的表现层

相对而言，数据（尤其是数据库）是一种更加抽象的、对计算机更高效和友好的数据表现形式，更多的存在于逻辑模型中。

URI（Uniform Resource Identifier，统一资源标识符）就是在IMS网络中IMS用户的“名字”，也就是IMS用户的身份标识。

###### 统一资源接口

RESTful架构风格规定，数据的元操作，即CRUD(create, read,update和delete,即数据的增删查改)操作，分别对应于HTTP方法：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源，这样就统一了数据操作的接口，仅通过HTTP方法，就可以完成对数据的所有增删查改工作。

| 请求                       | GET                                                          | POST                                     | PUT                                        | PATCH                                            | DELETE                                    |
| -------------------------- | ------------------------------------------------------------ | ---------------------------------------- | ------------------------------------------ | ------------------------------------------------ | ----------------------------------------- |
| 意义                       | SELECT                                                       | CREATE                                   | UPDATE                                     | UPDATE                                           | DELETE                                    |
| 解释                       | 从服务器取出资源（一项或多项                                 | 在服务器新建一个资源                     | 在服务器更新资源（客户端提供完整资源数据） | 在服务器更新资源（客户端提供需要修改的资源数据） | 从服务器删除资源                          |
| 使用（本人项目）           | 使用                                                         | 使用                                     | 使用                                       | 暂不使用                                         | 使用                                      |
| 请求成功时                 | 要返回对应的数据，及状态码200，即SUCCESS                     | -----                                    | 同GET                                      | 同GET                                            | -----                                     |
| 创建数据成功时             | -----                                                        | 要返回创建的数据，及状态码201，即CREATED | -----                                      | -----                                            | -----                                     |
| 删除数据成功时             | -----                                                        | -----                                    | -----                                      | -----                                            | 不返回数据，状态码要返回204，即NO CONTENT |
| 请求异常                   | 校验请求数据时发现错误，要返回状态码 400，即BAD REQUEST      | 同左侧                                   | 同左侧                                     | 同左侧                                           | 同左侧                                    |
| API 请求需要用户认证时     | 如果request中的认证信息不正确，要返回状态码 401，即NOT AUTHORIZED | 同左侧                                   | 同左侧                                     | 同左侧                                           | 同左侧                                    |
| API 请求需要验证用户权限时 | 如果当前用户无相应权限，要返回状态码 403，即FORBIDDEN        | 同左侧                                   | 同左侧                                     | 同左侧                                           | 同左侧                                    |

GET

- 安全且幂等
- 获取表示
- 变更时获取表示（缓存）

- 200（OK） - 表示已在响应中发出

- 204（无内容） - 资源有空表示
- 301（Moved Permanently） - 资源的URI已被更新
- 303（See Other） - 其他（如，负载均衡）
- 304（not modified）- 资源未更改（缓存）
- 400 （bad request）- 指代坏请求（如，参数错误）
- 404 （not found）- 资源不存在
- 406 （not acceptable）- 服务端不支持所需表示
- 500 （internal server error）- 通用错误响应
- 503 （Service Unavailable）- 服务端当前无法处理请求

POST

- 不安全且不幂等
- 使用服务端管理的（自动产生）的实例号创建资源
- 创建子资源
- 部分更新资源
- 如果没有被修改，则不过更新资源（乐观锁）

- 200（OK）- 如果现有资源已被更改

- 201（created）- 如果新资源被创建
- 202（accepted）- 已接受处理请求但尚未完成（异步处理）
- 301（Moved Permanently）- 资源的URI被更新
- 303（See Other）- 其他（如，负载均衡）
- 400（bad request）- 指代坏请求
- 404 （not found）- 资源不存在
- 406 （not acceptable）- 服务端不支持所需表示
- 409 （conflict）- 通用冲突
- 412 （Precondition Failed）- 前置条件失败（如执行条件更新时的冲突）
- 415 （unsupported media type）- 接受到的表示不受支持
- 500 （internal server error）- 通用错误响应
- 503 （Service Unavailable）- 服务当前无法处理请求

PUT

- 不安全但幂等
- 用客户端管理的实例号创建一个资源
- 通过替换的方式更新资源
- 如果未被修改，则更新资源（乐观锁）

- 200 （OK）- 如果已存在资源被更改

- 201 （created）- 如果新资源被创建
- 301（Moved Permanently）- 资源的URI已更改
- 303 （See Other）- 其他（如，负载均衡）
- 400 （bad request）- 指代坏请求
- 404 （not found）- 资源不存在
- 406 （not acceptable）- 服务端不支持所需表示
- 409 （conflict）- 通用冲突
- 412 （Precondition Failed）- 前置条件失败（如执行条件更新时的冲突）
- 415 （unsupported media type）- 接受到的表示不受支持
- 500 （internal server error）- 通用错误响应
- 503 （Service Unavailable）- 服务当前无法处理请求

DELETE

- 不安全但幂等
- 删除资源

- 200 （OK）- 资源已被删除

- 301 （Moved Permanently）- 资源的URI已更改
- 303 （See Other）- 其他，如负载均衡
- 400 （bad request）- 指代坏请求
- 404 （not found）- 资源不存在
- 409 （conflict）- 通用冲突
- 500 （internal server error）- 通用错误响应
- 503 （Service Unavailable）- 服务端当前无法处理请求

###### Serialization 和 Deserialization

> Serialization 和 Deserialization即序列化和反序列化。RESTful API以规范统一的格式作为数据的载体，常用的格式为json或xml，以json格式为例，当客户端向服务器发请求时，或者服务器相应客户端的请求，向客户端返回数据时，都是传输json格式的文本，而在服务器内部，数据处理时基本不用json格式的字符串，而是native类型的数据，最典型的如类的实例，即对象（object），json仅为服务器和客户端通信时，在网络上传输的数据的格式，服务器和客户端内部，均存在将json转为native类型数据和将native类型数据转为json的需求，其中，将native类型数据转为json即为序列化，将json转为native类型数据即为反序列化。虽然某些开发语言，如Python，其原生数据类型list和dict能轻易实现序列化和反序列化，但对于复杂的API，内部实现时总会以对象作为数据的载体，因此，确保序列化和反序列化方法的实现，是开发RESTful API最重要的一步准备工作。

> 序列化和反序列化是RESTful API开发中的一项硬需求，所以几乎每一种常用的开发语言都会有一个或多个优秀的开源库，来实现序列化和反序列化，因此，我们在开发RESTful API时，没必要制造重复的轮子，选一个好用的库即可。如实体类实现 **serializer** 序列化。

> 当然了，RESTful API 是写给开发者来消费的，其命名和结构需要有意义。因此，在设计和编写URL时，要符合一定的规范。

###### 无状态

所谓无状态的，即所有的资源，都可以通过URI定位，而且这个定位与其他资源无关，也不会因为其他资源的变化而改变。有状态和无状态的区别。如查询员工的工资，如果查询工资是需要登录系统，进入查询工资的页面，执行相关操作后，获取工资的多少，则这种情况是有状态的，因为查询工资的每一步操作都依赖于前一步操作，只要前置操作不成功，后续操作就无法执行；如果输入一个url即可得到指定员工的工资，则这种情况是无状态的，因为获取工资不依赖于其他资源或状态，且这种情况下，员工工资是一个资源，由一个url与之对应，可以通过HTTP中的GET方法得到资源，是典型的RESTful风格。

###### ROA、SOA与REST

注意：在这里不谈RPC，RPC风格曾是Web Service的主流；RPC风格的服务，不仅可以用HTTP，还可以用TCP或其他通信协议。同样的RPC风格的服务，受开发服务采用语言的束缚比较大；进入移动互联网时代后，RPC风格的服务很难在移动终端使用，而RESTful风格的服务，由于可以直接以json或xml为载体承载数据，以HTTP方法为统一接口完成数据操作，客户端的开发不依赖于服务实现的技术，移动终端也可以轻松使用服务，REST终将取代RPC成为web service的主导。

> ROA即Resource Oriented Architecture，RESTful架构风格的服务是围绕资源展开的，是典型的ROA架构（虽然“A”和“架构”存在重复，但说无妨），虽然ROA与SOA并不冲突，甚至把ROA看做SOA的一种也未尝不可，但由于RPC也是SOA，比较久远一点的论文、博客或图书也常把SOA与RPC混在一起讨论，因此，RESTful架构风格的服务通常被称之为ROA架构，很少提及SOA架构，以便更加显式的与RPC区分。

###### 认证机制

由于RESTful风格的服务是无状态的，认证机制尤为重要。例如一个隐私资源，只有本人或其他少数有权限的用户有资格看到，不通过权限认证机制对资源做一层限制，那么所有资源都将以公开方式暴露出来，很不合理的，同样也很危险。

当然这样的问题肯定是需要解决的，解决权限问题可以想到：自定义权限认证，Shiro，SpringSecurity，SpringCloud-Aouth认证。

###### OAuth

OAuth（开放授权）是一个开放的授权标准，允许用户让第三方应用访问该用户在某一web服务上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和密码提供给第三方应用。

OAuth允许用户提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。每一个令牌授权一个特定的第三方系统（例如，视频编辑网站)在特定的时段（例如，接下来的2小时内）内访问特定的资源（例如仅仅是某一相册中的视频）。这样，OAuth让用户可以授权第三方网站访问他们存储在另外服务提供者的某些特定信息，而非所有内容。

正是由于OAUTH的严谨性和安全性，现在OAUTH已成为RESTful架构风格中最常用的认证机制，和RESTful架构风格一起，成为企业级服务的标配。

#### SpringClound



**Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里**

**Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台**

**Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求**

**Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题**

- Hystrix dashboard 服务，对 Hystrix 进行实时监控的工具

- ```xml
  添加以下行会生成Hystrix DEBUG级别日志记录.
  logging:
    level:
     com.netflix.hystrix: DEBUG
  ```

- Turbine 服务，日志收集器，用于聚合 Hystrix 中的日志

**Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务**

![1609298416126](D:\Desktop\文件\拓展\拓展.assets\1609298416126.png)

![1609298680419](D:\Desktop\文件\拓展\拓展.assets\1609298680419.png)

##### 组件

###### **Eureka**

服务注册与发现	

Eureka Client：负责将这个服务的信息注册到Eureka Server中

用于简化Eureka Server的交互，客户端同时也具备一个内置的、 使用轮询（round-robin）负载算法的负载均衡器。在应用启动后，将会向Eureka Server发送心跳（默认周期为30秒），以证明当前服务是可用状态。如果Eureka Server在一定的时间（默认90秒）未收到客户端的心跳，Eureka Server将会从服务注册表中把这个服务节点移除。

Eureka Server：注册中心，里面有一个注册表，保存了各个服务所在的机器和端口号

Eureka Server在运行期间会统计心跳失败的比例在15分钟以之内是否低于85%，如果出现低于的情况，Eureka Server会将当前实例注册信息保护起来，让这些实例不会过期。（目的就是在该服务可能存在网络延迟等问题，服务其实没有真正的宕机，如果服务恢复了可以使他快速恢复，宁可保存，也不误剔除）但是这样做会使客户端很容易拿到实际已经不存在的服务实例，会出现调用失败的情况。因此客户端要有容错机制，比如请求重试、断路器。
也可以关闭自我保护属性：
eureka.server.enableSelfPreservation=true.
可以设置改参数值为false，以确保注册中心将不可用的实例删除。



![1609298234745](D:\Desktop\文件\拓展\拓展.assets\1609298234745.png)



###### **Feign**

**基于Netfix Feign实现，整合了SpringCloudRibbon和SpringCloudHystrix，除了提供这两者的强大功能外，还提供了一种声明式的Web服务客户端定义的方式。**

关键机制：动态代理

![1609298317199](D:\Desktop\文件\拓展\拓展.assets\1609298317199.png)

首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理；

接着你要是调用那个接口，本质就是会调用 Feign创建的动态代理，这是核心中的核心；

Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的服务的地址；

最后针对这个地址，发起请求、解析响应。

注解:

```powershell
	@EnableFeignClients //注解开启SpringCloudFeign的支持功能
	@FeignClient（name=指定服务名，fallback=指定降级类） //接口声明调用
```



###### **Ribbon**

![1609298347906](D:\Desktop\文件\拓展\拓展.assets\1609298347906.png)

Ribbon是和Feign以及Eureka紧密协作，完成工作的，具体如下：

首先Ribbon会从 Eureka Client里获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口号。

然后Ribbon就可以使用默认的Round Robin算法，从中选择一台机器

Feign就会针对这台机器，构造并发起请求。

###### **Hystrix**

Hystrix是一个用于处理分布式系统的延迟和容错的开源库,在分布式系统里,许多依赖不可避兔的会调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。Hystrix的出现就是为了解决雪崩效应。

 服务雪崩

多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C,微服务B和微服务C又调用其它的微服务，这就是所谓的“扇出”。如果扇出的链路上某个微服务的调用响应时间过长或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的”雪崩效应”。

服务熔断

熔断机制是应对雪崩效应的一种微服务链路保护机制。

当删除链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回”错误的响应信息。当检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值,缺省是5秒内20次调用失败就会启动熔断机制。熔断机制的注解是@HystrixCommand。

服务降级

整体资源快不够了，忍痛将某些服务先关掉，待渡过难关，再开启回来。



###### **Zuul**

Zuul的核心是一系列的filters，其作用可以类比Servlet框架的Filter，或者AOP。

Zuul包含了对请求的路由和过滤两个最主要的功能，是各种服务的统一入口，同时还会用来提供监控、授权、安全、调度等等。

路由功能：负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础。

过滤器功能：则负责对请求的处理过程进行干预，是实现请求校验、服务聚合等功能的基础。

Zuul和Eureka进行整合：将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获得其他微服务的消息,也即以后的访问微服务都是通过Zuul跳转后获得。

注意：Zuul服务最终还是会注册进Eureka，提供代理+路由+过滤三大功能。

1. **网关与过滤器区别**
   网关是拦截所有服务器请求进行控制
   过滤器拦截某单个服务器请求进行控制
2. **Nginx与Zuul的区别**
   Nginx是采用服务器负载均衡进行转发
   Zuul依赖Ribbon和eureka实现本地负载均衡转发
   相对来说Nginx功能比Zuul功能更加强大能够整合其他语言比如lua脚本实现强大的功能

###### Config

![1610589426726](D:\Desktop\文件\拓展\拓展.assets\1610589426726.png)

Spring Cloud Config是一个解决分布式系统的配置管理方案。

配置文件存储在远端Git（比如GitHub，Gitee等仓库），config-server从远端Git拉取配置文件，并保存到本地Git。

本地Git和config-server的交互是双向的，因为当远端Git无法访问时，会从本地Git获取配置文件。

Config Server：提供配置文件的存储、以接口的形式将配置文件的内容提供出去。

Config Client：通过接口获取数据、并依据此数据初始化自己的应用。

服务端(**@EnableConfigServer**):

```properties
spring.application.name=springcloud-config-server
server.port=8080
# 配置git仓库地址
spring.cloud.config.server.git.uri=https://github.com/13849141963/spring-config-file/
# 配置仓库的分支
spring.cloud.config.label=master
# 配置仓库路下的相对搜索位置.可以配置多个
spring.cloud.config.server.git.search-paths=respoitory
# 访问git仓库的用户名
spring.cloud.config.server.git.username=13849141963
# 访问git仓库的用户密码 如果Git仓库为公开仓库，可以不填写用户名和密码，如果是私有仓库需要填写
spring.cloud.config.server.git.password=********
```



- 远程Git仓库：用来存储配置文件的地方，上例中我们用来存储计划应用名为 didispace 的多环境配置文件！ didispace-{profile} .properties.
- Config Server:这是我们上面构建的分布式配置中心，springcloud-config-server工程，在该工程中指定了所要连接的Git仓库位置以及账户、密码等连接信息。
- 本地Git仓库：在springcloud-config-server的义件系统中，每次客户端请求获取配罝信息时，springcloud-config-server从Git仓库中获取最新配置到本地，然后在本地Git仓库中读取并返回。 当远程仓库无法获取时，直接将本地内容返回。
- Service A、 Service B:具体的微服务应用，它们指定了 spriongcloud-config-server的地址，从而实现从外部化获取应用自己要只的配置信息。这些应用在启动的时候，会向springcloud-config-server请求获取配罝信息来进行加载

![img](D:\Desktop\文件\拓展\拓展.assets\20181105193730422.png)

 

 客户端： 

```properties
#bootstrap.yml

spring.application.name=springcloud-config-client
# 指明远程仓库的分支
spring.cloud.config.label=master
# dev开发环境配置文件   test测试环境    pro正式环境
spring.cloud.config.profile=dev
# 配置中心config-server的地址
spring.cloud.config.uri=http://10.0.45.103:8080/
server.port=7001
```

应用从配置管理中获取配置信息遵从下面的执行流程：
1、应用后动时，根据 bootstrap. properties中配置的应用名{ application}，坏境名{profile}、分支名{label}，向ConfigServer请求获取配置信息
2、CmifigServer根据自己维护的Git仓库信息和客户端传递过来的配置定位信息去査找配置信息。
3、通过git clone命令将找到的配置信息下载到Config Server的文件系统中。
4、Config Server 创建 Spring 的 ApplicationContent 实例，并从Git 本地仓库中加载配置文件，最后将这些配置内容读取出来返回给客户端应用。
5、客户端应用在获得外部配置文件后加载到客户端的 ApplicationContext实例，该配置内容的优先级高于客户端Jar包内部的配置内容，所以在ja i包中重复的内容将不再被加载。

Config Server巧妙地通过git clone将配罝信息存于本地，起到了缓存的作用，即使当Git服务端无法访问的时候，依然可以取Config Server中的缓存内容进行使用。

**自动刷新**

1、ConfigServer(配置中心服务端)从远端git拉取配置文件并在本地git一份，ConfigClient（微服务）从ConfigServer端获取自己对应 配置文件；

2、当远端git仓库配置文件发生改变，ConfigServer如何通知到ConfigClient端，即ConfigClient如何感知到配置发生更新？

Spring Cloud Bus会向外提供一个http接口，即图中的/bus/refresh。我们将这个接口配置到远程的git的webhook上，当git上的文件内容发生变动时，就会自动调用/bus-refresh接口。Bus就会通知config-server，config-server会发布更新消息到消息总线的消息队列中，其他服务订阅到该消息就会信息刷新，从而实现整个微服务进行自动刷新。

![1610590554796](D:\Desktop\文件\拓展\拓展.assets\1610590554796.png)

1、提交配置触发post请求给server端的bus/refresh接口

2、server端接收到请求并发送给Spring Cloud Bus总线

3、Spring Cloud bus接到消息并通知给其它连接到总线的客户端

4、其它客户端接收到通知，请求Server端获取最新配置

5、全部客户端均获取到最新的配置

##### SpringCloud与Dubbo区别

```markdown
为什么放弃Dubbo 使用SpringCloud？


相同点：SpringCloud 和Dubbo可以实现RPC远程调用框架，可以实现服务治理。

不同点:
SpringCloud是一套目前比较网站微服务框架了，整合了分布式常用解决方案遇到了问题注册中心Eureka、负载均衡器Ribbon ，客户端调用工具Rest和Feign，分布式配置中心Config，服务保护Hystrix，网关Zuul Gateway ，服务链路Zipkin，消息总线Bus等。 

从架构上分析
Dubbo内部实现功能没有SpringCloud强大，只是实现服务治理，缺少分布式配置中心、网关、链路、总线等，如果需要用到这些组件，需要整合其他框架。

从更新迭代速度分析
Dubbo目前更新速度没有SpringCloud快，到SpringCloud2.0后SpringCloud会越来完善和稳定。

从开发背景角度分析
Dubbo的开发背景是阿里巴巴， 在中国也推出了非常多的优秀的开源框架
但是在SpringCloud的背景是Spring家族，Spring是专注于企业级开源框架开发，在中国，或者在整个世界上Spring框架都应用的非常广泛。所有相对来说SpringCloud的背景比Dubbo更加强大。

最后总结下：如果学习Dubbo的话，学习其他的分布式解决方案需要自己组装，反而如果学习SpringCloud，它已经把整个常用分布式解决都整合好了。



SpringCloud与Dubbo区别


相同点:都是rpc远程调用框架，可以实现服务治理（管理服务关系注册中心）

不同点：springcloud是目前比就完善的微服务框架，整合了netflix，集成了注册中心Eureka,负载均衡ribbon,客户端调用工具feign，分布式配置中心cofig,服务保护Hystrix，网关zuul gateway,服务链路zipkin,消息总线bus，

架构方面：
dubbo只有实现了服务治理，负载均衡，其他组件需要自己集成第三方应用，而springcloud已经帮忙集成所有组件，所以使用整合更加完善。

更新迭代方面
Dubbo更新缓慢，前几年基本无更新，springcloud更新维护快，更加完善稳定。

开发背景分析
dubbo是阿里开发，在国内是比较认可的，但是springcloud是spring家族开发的，国际化使用，专门专注开源框架开发，在全球使用更加广泛。

总结
Dubbo如果开发许多组件没有集成不完善，需要主动集成第三方组件，springcloud已经帮我们集成，只需要引入依赖和注解就搞定了，简单，稳定，快捷。
```

##### **Ribbon和Feign** 

在微服务架构中，业务都会被拆分成一个独立的服务，服务与服务的通讯是基于HTTP RESTful的。Spring Cloud有两种服务调用方式，一种是Ribbon+RestTemplate，另一种是Feign。

Feign目标使编写Java Http客户端变得更容易

在使用Ribbon+ RestTemplate时，Ribbon需要自己构建http请求，模拟http请求然后使用RestTemplate发送给其他服务，步骤相当繁琐。利用RestTemplate对http请求的封装处理，形成了-套模版化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处,往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一些客户端类来包装这些依赖服务的调用。所以，Feign在此基础上做了进一步封装，由他来帮助我们定义和实现依赖服务接口的定义。

在Feign的实现下，我们只需创建一个接口并使用注解的方式来配置它（以前是Dao接口上面标注Mapper注解，现在是一个微服务接口上面标注一个Feign注解即可）， 即可完成对服务提供方的接口绑定，简化了使用Spring Cloud Ribbon时，自动封装服务调用客户端的开发量。

Ribbon通过轮询实现了客户端的负载均衡，而与Ribbon不同的是，Feign是一个声明式的Web服务客户端， 使得编写Web服务客户端变得非常容易，只需要创建一个接口， 然后在上面添加注解，像调用本地方法一样调用它就可以，而感觉不到是调用远程方法。SpringCloud中Feign默认集成了Ribbon，并和Eureka结合，默认实现了负载均衡的效果。

#### **[Zookeeper](https://blog.csdn.net/fenglongmiao/article/details/79305010)**

ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户 。

**提供了什么？**

- 文件系统

  ```markdown
  	每个子目录项如 NameService 都被称作为znode，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的不同在于znode是可以存储数据的。
  有四种类型的znode：  
  1、PERSISTENT-持久化目录节点  
  客户端与zookeeper断开连接后，该节点依旧存在  
  
  2、PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点  
  客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号  
  
  3、EPHEMERAL-临时目录节点  
  客户端与zookeeper断开连接后，该节点被删除  
  
  4、EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点  
  客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号  
  ```

- 通知机制

```markdown
		客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。
```

**做了什么？**

- 命名服务

```markdown
		在zookeeper的文件系统里创建一个目录，即有唯一的path。在我们使用tborg无法确定上游程序的部署机器时即可与下游程序约定好path，通过path即能互相探索发现。 
```

- 配置管理

```markdown
		程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好 
```

![1609220846167](D:\Desktop\文件\拓展\拓展.assets\1609220846167.png)

- 集群管理

```markdown
		所谓集群管理无在乎两点：是否有机器退出和加入、选举master。  

		对于第一点，所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。 

		新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。 
```

![1609220924293](D:\Desktop\文件\拓展\拓展.assets\1609220924293.png)

- 分布式锁

```markdown
		有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。  

		对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放出锁。  

		对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。
```

![1609221013397](D:\Desktop\文件\拓展\拓展.assets\1609221013397.png)

- 队列管理

```markdown
	两种类型的队列： 

1、同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。  

2、队列按照 FIFO 方式进行入队和出队操作。  

第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。  

第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。 
```

##### 设计目的

-  最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。  

- 可靠性：具有简单、健壮、良好的性能，如果消息被到一台服务器接受，那么它将被所有的服务器接受。  

- 实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。  

- 等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。  

- 原子性：更新只能成功或者失败，没有中间状态。  

- 顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。  


##### 工作原理

![1609213471292](D:\Desktop\文件\拓展\拓展.assets\1609213471292.png)

  Zookeeper 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。

当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。  

每个Server在工作过程中有三种状态：  

LOOKING：当前Server不知道leader是谁，正在搜寻 
​	LEADING：当前Server即为选举出来的leader 
​	FOLLOWING：leader已经选举出来，当前Server与之同步   

为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。   

##### 选主流程

当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。

Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。

fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。 

![1609213907995](D:\Desktop\文件\拓展\拓展.assets\1609213907995.png)

##### 分布式与数据复制

Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处：  

1、容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作；  

2、提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力；  

3、提高性能：让客户端本地访问就近的节点，提高用户访问速度。  

从客户端读写访问的透明度来看，数据复制集群系统分下面两种：  

1、写主(WriteMaster) ：对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离；  

2、写任意(Write Any)：对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。 

对zookeeper来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这也是它建立observer的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。  

#### **[Nginx](https://blog.csdn.net/qq_45043948/article/details/109248035)**

- Nginx是一个高性能HTTP和反向代理web服务器
- 主要功能反向代理
- 集群和负载均衡
- 静态资源虚拟化

##### nginx.conf配置结构

![1609208661103](D:\Desktop\文件\拓展\拓展.assets\1609208661103.png)

```properties
#user  nobody; # 执行进行的用户
worker_processes  2; # worker进程的个数，一般设置为和cpu个数相同

# 设置日志级别 级别：debug info notice warn error crit
#error_log  logs/error.log;   
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid; # 设置pid文件的路径


events {
	# 每个worker进程允许的最大客户端连接数
    worker_connections  1024;
}


http {
	# 引入外部配置文件
    include       mime.types;
    default_type  application/octet-stream;
	# 日志的配置
    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

    sendfile        on; # 用于文件的传输
    #tcp_nopush     on;	# 数据包累计到一定的大小后才进行发送

    #keepalive_timeout  0; # 经过默认时间后关闭tcp连接，如果设置为0，每次都会使用一个新的连接
    keepalive_timeout  65;

    #gzip  on;	# 数据压缩

    server {
        listen       80; # 监听端口
        server_name  localhost; # 监听ip

        #charset koi8-r;

        #access_log  logs/host.access.log  main;
		# 路由 
        location / {
            root   html;
            index  index.html index.htm;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }

        # proxy the PHP scripts to Apache listening on 127.0.0.1:80
        #
        #location ~ \.php$ {
        #    proxy_pass   http://127.0.0.1;
        #}

        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        #
        #location ~ \.php$ {
        #    root           html;
        #    fastcgi_pass   127.0.0.1:9000;
        #    fastcgi_index  index.php;
        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
        #    include        fastcgi_params;
        #}

        # deny access to .htaccess files, if Apache's document root
        # concurs with nginx's one
        #
        #location ~ /\.ht {
        #    deny  all;
        #}
    }


    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    #server {
    #    listen       8000;
    #    listen       somename:8080;
    #    server_name  somename  alias  another.alias;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}


    # HTTPS server
    #
    #server {
    #    listen       443 ssl;
    #    server_name  localhost;

    #    ssl_certificate      cert.pem;
    #    ssl_certificate_key  cert.key;

    #    ssl_session_cache    shared:SSL:1m;
    #    ssl_session_timeout  5m;

    #    ssl_ciphers  HIGH:!aNULL:!MD5;
    #    ssl_prefer_server_ciphers  on;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}

}
```

##### Nginx解决跨域问题

在server项中加入如下配置

```properties
#允许跨域请求的域，*代表所有 
add_header 'Access-Control-Allow-Origin' *; 
#允许带上cookie请求 
add_header 'Access-Control-Allow-Credentials' 'true'; 
#允许请求的方法，比如 GET/POST/PUT/DELETE 
add_header 'Access-Control-Allow-Methods' *; 
#允许请求的header 
add_header 'Access-Control-Allow-Headers' *;
```

![1609210143458](D:\Desktop\文件\拓展\拓展.assets\1609210143458.png)

##### 负载均衡

**轮询**(Nginx默认的负载均衡算法)

**权重**

```properties
 upstream www.tomcats.com {
        server 192.168.33.10:8081 weight=1;
        server 192.168.33.10:8082 weight=2;
        server 192.168.33.10:8083 weight=10;
    }

#upstream指令参数
#max_conns --最大连接数
#slow_start --慢启动如果设置了权重，权重会慢慢增加，而不是直接变成相应的权重。商业版才有这个参数
#down --配置服务器为不可用
#backup --备份，当有服务器出现问题全部下线的时候，才会启动
#max_fails=2 --允许失败的最大次数
#fail_timeout=2s --达到最大失败次数后，规定时间内不再请求这个服务器，而去请求其他的服务器。在这个规定时间过去后，会再次尝试请求这个服务器
#max_fails和fail_timeout需要搭配使用
#keepalive --保持的长连接的数量，节省频繁的创建和关闭连接使用的资源
```

**ip_hash**

```properties
hash(ip) % node_counts = index
```

只要ip不变化，请求都会到同一个tomcat服务器

```properties
    upstream www.tomcats.com {
        ip_hash;
        server 192.168.33.10:8081;
        server 192.168.33.10:8082;
        server 192.168.33.10:8083;
        keepalive 32;
    }
```

如果我们要下线一台服务器，我们应该在服务器后面加载`down`，而不是直接删除掉这台服务器，否则的话ip_hash会重新进行计算，那么同一个ip的请求就有可能去到其他服务器，会话状态无法保持。

**url_hash**

根据请求路径（字符串）的不同，转发到不同的tomcat服务器

```properties
    upstream www.tomcats.com {
        hash $request_uri;
        server 192.168.33.10:8081;
        server 192.168.33.10:8082;
        server 192.168.33.10:8083;
        keepalive 32;
    }
```

**least_conn**

哪台服务器的连接数少，请求哪台。

```properties
    upstream www.tomcats.com {
        least conn;
        server 192.168.33.10:8081;
        server 192.168.33.10:8082;
        server 192.168.33.10:8083;
        keepalive 32;
    }
```

##### Nginx的反向代理缓存

将缓存存储到nginx的指定目录中

```properties
# proxy_cache_path 设置缓存保存的目录
# keys_zone 设置共享内存以及占用空间的大小
# max_size 设置缓存大小
# inactive 超过该时间不访问缓存，则缓存被清理
# use_temp_path 关闭临时目录
proxy_cache_path /usr/local/nginx/upstream_cache
keys_zone=mycache:5m
max_size=1g
inactive=30s
use_temp_path=off;

    server {
        listen       80;
        server_name  localhost;            
        # 开启并使用缓存
        proxy_cache mycache;
        # 对于状态为200和304的缓存文件的缓存时间是2分钟
        proxy_cache_valid 200 304 2m;
}
```

#### **Redis**

##### 缓存问题

**缓存穿透**

![1609206070174](D:\Desktop\文件\拓展\拓展.assets\1609206070174.png)

缓存穿透是指**缓存服务器中没有缓存数据，数据库中也没有符合条件的数据，导致业务系统每次都绕过缓存服务器查询下游的数据库，缓存服务器完全失去了其应用的作用。**

解决：

​	缓存空值：**可以为这些key对应的值设置为null并放到缓存中，这样再出现查询这个key 的请求的时候，直接返回null即可 。**

​	布隆过滤器(Bloom Filter)：**可以将查询的数据条件都哈希到一个足够大的布隆过滤器中，用户发送的请求会先被布隆过滤器拦截，一定不存在的数据就直接拦截返回了，从而避免下一步对数据库的压力。**

**缓存击穿**

![1609206315852](D:\Desktop\文件\拓展\拓展.assets\1609206315852.png)

缓存击穿是指**当某一key的缓存过期时大并发量的请求同时访问此key，瞬间击穿缓存服务器直接访问数据库，让数据库处于负载的情况。**

解决：

​	异步定时更新：**某一个热点数据的过期时间是1小时，那么每59分钟，通过定时任务去更新这个热点key，并重新设置其过期时间。**

​	互斥锁：**在缓存处理上，通常使用一个互斥锁来解决缓存击穿的问题。简单来说就是当Redis中根据key获得的value值为空时，先锁上，然后从数据库加载，加载完毕，释放锁。若其他线程也在请求该key时，发现获取锁失败，则先阻塞。**

**缓存雪崩**

![1609206485673](D:\Desktop\文件\拓展\拓展.assets\1609206485673.png)

缓存雪崩是指**当大量缓存同时过期或缓存服务宕机，所有请求的都直接访问数据库，造成数据库高负载，影响性能，甚至数据库宕机。**

解决：

​	不同的过期时间：**为了避免大量的缓存在同一时间过期，可以把不同的key过期时间设置成不同的， 并且通过定时刷新的方式更新过期时间。**

​	集群：**在缓存雪崩问题防治上面，一个比较典型的技术就是采用集群方式部署，使用集群可以避免服务单点故障。**

##### 分布式锁

三种实现方式：1.数据库乐观锁；2.基于Redis的分布式锁；3.基于Zookeeper的分布式锁

分布式锁的四个满足条件：

1.互斥性。在任意时刻，只有一个客户端能持有锁。
​	2.不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
​	3.具有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
​	4.解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。

**Redis分布式锁**

Jedis

加锁：

```java
public class RedisTool {

    private static final String LOCK_SUCCESS = "OK";
    private static final String SET_IF_NOT_EXIST = "NX";
    private static final String SET_WITH_EXPIRE_TIME = "PX";

    /**
     * 尝试获取分布式锁
     * @param jedis Redis客户端
     * @param lockKey 锁
     * @param requestId 请求标识
     * @param expireTime 超期时间
     * @return 是否获取成功
     */
    public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) {

        String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime);

        if (LOCK_SUCCESS.equals(result)) {
            return true;
        }
        return false;

    }

}


可以看到，我们加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有五个形参：

第一个为key，我们使用key来当锁，因为key是唯一的。

第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。

第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作；

第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。

第五个为time，与第四个参数相呼应，代表key的过期时间。

总的来说，执行上面的set()方法就只会导致两种结果：1. 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。2. 已有锁存在，不做任何操作。
```

解锁：

```java
public class RedisTool {

    private static final Long RELEASE_SUCCESS = 1L;

    /**
     * 释放分布式锁
     * @param jedis Redis客户端
     * @param lockKey 锁
     * @param requestId 请求标识
     * @return 是否释放成功
     */
    public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) {

        String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
        Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId));

        if (RELEASE_SUCCESS.equals(result)) {
            return true;
        }
        return false;

    }

}
```



##### 持久化

**RDB**

RDB持久化是把当前进程数据生成快照保存到硬盘的过程。

RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照。

Redis加载RDB恢复数据远远快于AOF的方式，无法做到实时持久化，一般用于数据冷备和复制传输。

**AOF**

以独立日志的方式记录每次的写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的。AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式。

#### **Eureka**

**Eureka心跳机制**

​          在应用启动后，节点们将会向Eureka Server发送心跳,默认周期为30秒，如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，Eureka Server将会从服务注册表中把这个服务节点移除(默认90秒)。

**Eureka自我保护模式原理**
默认情况下，如果在15分钟内超过85%的客户端节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障(比如网络故障或频繁的启动关闭客户端)，Eureka Server自动进入自我保护模式。不再剔除任何服务，当网络故障恢复后，该节点自动退出自我保护模式。

```xml
eureka:
  server:
    #自我保护模式，当出现网络分区故障、频繁的开启关闭客户端、eureka在短时间内丢失过多客户端时，会进入自我保护模式，即一个服务长时间没有发送心跳，eureka也不会将其删除，默认为true
    enable-self-preservation: true
    #eureka server清理无效节点的时间间隔，默认60000毫秒，即60秒
    eviction-interval-timer-in-ms: 60000
    #阈值更新的时间间隔，单位为毫秒，默认为15 * 60 * 1000
    renewal-threshold-update-interval-ms: 15 * 60 * 1000
    #阈值因子，默认是0.85，如果阈值比最小值大，则自我保护模式开启
    renewal-percent-threshold: 0.85
    #清理任务程序被唤醒的时间间隔，清理过期的增量信息，单位为毫秒，默认为30 * 1000
    delta-retention-timer-interval-in-ms: 30000
```

自我保护模式是一种对网络异常的安全保护措施。使用自我保护模式让Eureka集群更加的健壮、稳定。

**关闭 Eureka 的自我保护模式**
可以使用eureka.server.enable-self-preservation=false来禁用自我保护模式，**适合在开发/测试环境中使用，生产环境建议打开自我保护模式。**

对于开发/测试环境的 Eureka Server，个人更建议关闭它的自我保护模式，因为你可能需要不断的开启与关闭实例，如果并未关闭自我保护模式，那么很容易就会触发自我保护模式，此时对调试会相对比较麻烦。

但是关闭自我保护模式，会有另外一个可能的问题，即隔一段时间后，可能会发生实例并未关闭，却无法通过网关访问了，此时很可能是由于网络问题，导致实例（或网关）与 Eureka Server 断开了连接，Eureka Server 已经将其注销（网络恢复后，实例并不会再次注册），此时重启 Eureka Server 节点或实例，并等待一小段时间即可。

关闭自我保护模式，可以在服务端和客户端配置。

```xml
服务端配置：
eureka:
  server:
    enable-self-preservation: false
    #eureka server清理无效节点的时间间隔，默认60000毫秒，即60秒
    eviction-interval-timer-in-ms: 60000 # 单位毫秒

客户端配置：
# 心跳检测检测与续约时间
# 测试时将值设置设置小些，保证服务关闭后注册中心能及时踢出服务
eureka:
  instance:
    lease-renewal-interval-in-seconds: 1
    lease-expiration-duration-in-seconds: 2
配置说明
lease-renewal-interval-in-seconds 每间隔1s，向服务端发送一次心跳，证明自己依然”存活“。
lease-expiration-duration-in-seconds  告诉服务端，如果我2s之内没有给你发心跳，就代表我“死”了，请将我踢掉。
```

**Eureka的健康检查**
![img](https://img2018.cnblogs.com/blog/270324/201812/270324-20181209012001459-1547908676.png)
说明：在Status栏显示着UP，表示应用程序状态正常。其它取值DOWN、OUT_OF_SERVICE、UNKNOWN等，只有UP的微服务会被请求。

由于Eureka Server与Eureka Client之间使用心跳机制来确定Eureka Client的状态，默认情况下，服务器端与客户端的心跳保持正常，应用程序就会始终保持“UP”状态，所以微服务的UP并不能完全反应应用程序的状态。

Spring Boot Actuator提供了/health端点，该端点可展示应用程序的健康信息，只有将该端点中的健康状态传播到Eureka Server就可以了，实现这点很简单，只需为微服务配置如下内容：
\#开启健康检查（需要spring-boot-starter-actuator依赖）

```csharp
eureka.client.healthcheck.enabled = true
```

如果需要更细粒度健康检查，可实现com.netflix.appinfo.HealthCheckHandler接口 。 EurekaHealthCheckHandler 已实现了该接口

#### Consul

#### Nacos

> 阿里的一个开源产品，是针对微服务架构中的服务发现、配置管理、服务治理的综合型解决方案。
>
> （用来实现配置中心和服务注册中心）

##### 	四大功能

- 服务发现和服务健康监测

  （使服务更容易注册，并通过DNS或HTTP接口发现其他服务，还提供服务的实时健康检查，以防 止向不健康的主机或服务实例发送请求。 ）

  - 支持基于DNS和基于RPC的服务发现。服务提供者使用原生SDK、OpenAPI、或一个独立的Agent TODO注册 Service 后，服务消费者可以使用DNS TODO 或HTTP&API查找和发现服务。
  - Nacos提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos 支持传输层 (PING 或 TCP)和应用层 (如 HTTP、MySQL、用户自定义）的健康检查。 对于复杂的云环境和网络拓扑环境中（如 VPC、边缘网络等）服务的健康检查，Nacos 提供了 agent 上报模式和服务端主动检测2种健康检查模式。Nacos 还提供了统一的健康检查仪表盘，帮助您根据健康状态管理服务的可用性及流量。

- 动态配置服务

  - 以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。
  - 消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效和敏捷。
  - 配置中心化管理让实现无状态服务变得更简单，让服务按需弹性扩展变得更容易。
  - 提供了一个简洁易用的UI (控制台样例 Demo) 帮助管理所有的服务和应用的配置。
  - Nacos 还提供包括配置版本跟踪、金丝雀发布、一键回滚配置以及客户端配置更新状态跟踪在内的一系列开箱即用的配置管理特性，能更安全地在生产环境中管理配置变更和降低配置变更带来的风险。

- 动态 DNS 服务

  - 动态 DNS 服务支持权重路由，更容易地实现中间层负载均衡、更灵活的路由策略、流量控制以及数据中心内网的简单DNS解析服务。动态DNS服务还能更容易地实现以 DNS 协议为基础的服务发现，消除耦合到厂商私有服务发现 API 上的风险。
  - Nacos 提供了一些简单的 DNS APIs TODO ，管理服务的关联域名和可用的 IP:PORT 列表

- 服务及其元数据管理

  - 从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述、生命周期、服务的静态依赖分析、服务的健康状态、服务的流量管理、路由及安全策略、服务的 SLA 以及最首要的 metrics 统计数据。

##### 服务发现

在微服务架构中一个业务流程需要多个微服务通过网络接口调用完成业务处理，服务消费方从服务注册中心获取服 务提供方的地址，从而进行远程调用，这个过程叫做服务发现。

![1609221846838](D:\Desktop\文件\拓展\拓展.assets\1609221846838.png)

服务实例本身并不记录服务生产方的网络地址，所有服务实例内部都会包含服务发现客户端。

1. 在每个服务启动时会向服务发现中心上报自己的网络位置。在服务发现中心内部会形成一个服务注册表，服务注册表是服务发现的核心部分，是包含所有服务实例的网络地址的数据库。
2. 服务发现客户端会定期从服务发现中心同步服务注册表 ，并缓存在客户端。
3. 当需要对某服务进行请求时，服务实例通过该注册表，定位目标服务网络地址。若目标服务存在多个网络地址，则使用负载均衡算法从多个服务实例中选择出一个，然后发出请求。

> 总结，在微服务环境中，由于服务运行实例的网络地址是不断动态变化的，服务实例数量的动态变化 ，因此无法使用固定的配置文件来记录服务提供方的网络地址，必须使用动态的服务发现机制用于实现微服务间的相互感知。 各服务实例会上报自己的网络地址，这样服务中心就形成了一个完整的服务注册表，各服务实例会通过服务发现中心来获取访问目标服务的网络地址，从而实现服务发现的机制。

|                 | **Nacos**                  | **Eureka**  | **Consul**        | **CoreDNS** | **Zookeeper** |
| --------------- | -------------------------- | ----------- | ----------------- | ----------- | ------------- |
| 一致性协议      | CP+AP                      | AP          | CP                | —           | CP            |
| 健康检查        | TCP/HTTP/MYSQL/Client Beat | Client Beat | TCP/HTTP/gRPC/Cmd | —           | Keep Alive    |
| 负载均衡策略    | 权重/ metadata/Selector    | Ribbon      | Fabio             | RoundRobin  | —             |
| 雪崩保护        | 有                         | 有          | 无                | 无          | 无            |
| 自动注销实例    | 支持                       | 支持        | 支持              | 不支持      | 支持          |
| 访问协议        | HTTP/DNS                   | HTTP        | HTTP/DNS          | DNS         | TCP           |
| 监听支持        | 支持                       | 支持        | 支持              | 不支持      | 支持          |
| 多数据中心      | 支持                       | 支持        | 支持              | 不支持      | 不支持        |
| 跨注册中心同步  | 支持                       | 不支持      | 支持              | 不支持      | 不支持        |
| SpringCloud集成 | 支持                       | 支持        | 支持              | 不支持      | 支持          |
| Dubbo集成       | 支持                       | 不支持      | 支持              | 不支持      | 支持          |
| K8S集成         | 支持                       | 不支持      | 支持              | 支持        | 不支持        |

#### Shiro

![1609226539794](D:\Desktop\文件\拓展\拓展.assets\1609226539794.png)

![1609226446724](D:\Desktop\文件\拓展\拓展.assets\1609226446724.png)

#### [Spring Security](https://blog.csdn.net/bao19901210/article/details/52574340)

spring security实现方式大致可以分为这几种：

​    1.配置文件实现，只需要在配置文件中指定拦截的url所需要权限、配置userDetailsService指定用户名、密码、对应权限，就可以实现。

​    2.实现UserDetailsService，loadUserByUsername(String userName)方法，根据userName来实现自己的业务逻辑返回UserDetails的实现类，需要自定义User类实现UserDetails，比较重要的方法是getAuthorities()，用来返回该用户所拥有的权限。

​    3.通过自定义filter重写spring security拦截器，实现动态过滤用户权限。

​    4.通过自定义filter重写spring security拦截器，实现自定义参数来检验用户，并且过滤权限。

#### Swagger

依赖

```xml
 <!-- Swagger核心包 start -->
 <dependency>
   <groupId>io.springfox</groupId>
   <artifactId>springfox-swagger2</artifactId>
   <version>2.6.1</version>
 </dependency>
 <dependency>
    <groupId>io.springfox</groupId>
    <artifactId>springfox-swagger-ui</artifactId>
    <version>2.6.1</version>
 </dependency>
<!-- Swagger核心包 end -->
```

application.yml

```yaml
# 配置eureka获取服务地址
eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:1001/eureka/
  # 配置Swagger相关信息
  instance:
      prefer-ip-address: true
      instanceId: ${spring.cloud.client.ipAddress}:${server.port}
      status-page-url: 
	  http://${spring.cloud.client.ipAddress}:${server.port}/swagger-ui.html 
      # ${server.port}为该服务的端口号
```

配置类

```java
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import springfox.documentation.builders.ApiInfoBuilder;
import springfox.documentation.builders.PathSelectors;
import springfox.documentation.builders.RequestHandlerSelectors;
import springfox.documentation.service.ApiInfo;
import springfox.documentation.spi.DocumentationType;
import springfox.documentation.spring.web.plugins.Docket;
import springfox.documentation.swagger2.annotations.EnableSwagger2;

@Configuration
@EnableSwagger2
public class SwaggerConfig {
    @Bean
    public Docket userApi() {
        Docket docket = new Docket(DocumentationType.SWAGGER_2)
                .apiInfo(apiInfo())
                .select()
                						  .apis(RequestHandlerSelectors.basePackage("cn.zhangbox.eureka.provider.controller"))//过滤的接口
                .paths(PathSelectors.any())
                .build();
        return docket;
    }


    private ApiInfo apiInfo() {
        return new ApiInfoBuilder().title("eureka服务端提供者接口平台").description("服务相关数据接口")
                .termsOfServiceUrl("http://www.zhang.box.cn/").contact("技术开发部")
                .license("Licence Version 1.0").licenseUrl("#").version("1.0").build();
    }

}
```



**配置详情解释：**

通过@Configuration注解，让Spring-boot来加载该类配置。

再通过@EnableSwagger2注解来启用Swagger2Configuration。

再通过userApi函数创建Docket的Bean之后，apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中）。
select() 函数返回一个 ApiSelectorBuilder 实例用来控制哪些接口暴露给Swagger2来展现。
一般采用指定扫描的包路径来定义。Swagger会扫描该包下所有Controller定义的API，并产生文档内容（除了被@ApiIgnore指定的请求）。

| 注解               | 作用                                                         |
| ------------------ | ------------------------------------------------------------ |
| @Api               | 用在类上，说明该类的作用                                     |
| @ApiOperation      | 用在方法上，说明方法的作用，标注在具体请求上，value和notes的作用差不多，都是对请求进行说明；tags则是对请求进行分类的，比如你有好几个controller，分别属于不同的功能模块，那这里我们就可以使用tags来区分了，看上去很有条理 |
| @ApiImplicitParams | 用在方法上包含一组参数说明                                   |
| @ApiImplicitParam  | 用在@ApiImplicitParams注解中，指定一个请求参数的各个方面     |
| @ApiResponses      | 用于表示一组响应                                             |
| @ApiResponse       | 用在@ApiResponses中，一般用于表达一个错误的响应信息          |
| @ApiModel          | 描述一个Model的信息（这种一般用在post创建的时候，使用@RequestBody这样的场景，请求参数无法使用@ApiImplicitParam注解进行描述的时候）表明这是一个被swagger框架管理的model，用于class上 |
| @ApiModelProperty  | 这里顾名思义，描述一个model的属性，就是标注在被标注了@ApiModel的class的属性上，这里的value是对字段的描述，example是取值例子，注意这里的example很有用，对于前后端开发工程师理解文档起到了关键的作用，因为会在api文档页面上显示出这些取值来；这个注解还有一些字段取值，可以自己研究，举例说一个：position，表明字段在model中的顺序 |

#### FreeMarker，Thymleaf



#### Git，SVN



**SVN：**集中版本控制系统，版本库集中放在中央服务器；开发人员从中央服务器下载最新版本，开发后将自己的代码提交到中央服务器；

缺点：服务器单点故障（服务器出现问题，开发环境都无法正常使用）；容错性差；

**Git：**分布式版本控制系统，（Distributed Version Control System，DVCS），分为本地仓库和远程仓库；

本地仓库：开发人员电脑上的Git仓库；

远程仓库：远程服务器上的Git仓库；

Clone 克隆，将远程仓库复制到本地；

Push 推送，将本地仓库代码上传到远程仓库；

Pull 拉取，将远程仓库代码下载到本地仓库。

![1610329230012](D:\Desktop\文件\拓展\拓展.assets\1610329230012.png)

**区别：**

1、Git 是分布式的，SVN 不是：Git 和其它非分布式的版本控制系统（SVN，CVS 等）最核心的区别。

2、Git 把内容按元数据方式存储，而 SVN 是按文件：所有的资源控制系统都是把文件的元信息隐藏在一个类似 .svn、.cvs 等的文件夹里。

3、Git 分支和 SVN 的分支不同：分支在 SVN 中一点都不特别，其实它就是版本库中的另外一个目录。

4、Git 没有一个全局的版本号，而 SVN 有：目前为止这是跟 SVN 相比 Git 缺少的最大的一个特征。

5、Git 的内容完整性优于 SVN：Git 的内容存储使用的是 SHA-1 哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏。



#### ElasticSearch

Elasticsearch -> 索引库Indices -> 类型Types -> 文档Documents -> 字段Fields

#### Http与TCP

 TCP协议对应于**传输层**，而Http协议对应于**应用层**，从本质上讲，二者没有可比性，Http协议是建立在TCP协议之上的，当浏览器需要从服务器获取网页数据的时候，会发出一次Http请求。Http会通过tcp建立起一个到服务器的连接通道，当本次请求需要的数据完毕后,Http会立即将TCP连接断开，这个过程是很短的。

Http是无状态的短连接，TCP是有状态的长链接

tcp传输快：

- **TCP协议**位于传输层，提供可靠的字节流服务。
- 为了方便传输，将大块数据分割成以**报文段**为单位的数据包进行管理，这样能更容易传输大数据。而且TCP协议能够确认数据最终是否送达到对方（**三次握手策略**）。

#### Tomcat

##### Tomcat是什么？

- Tomcat 服务器Apache软件基金会项目中的一个核心项目，是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用。
- 比方说，我有个web项目是想让他运行，就可以在运行在tomcat平台上，如果开启就可以运行访问，如果停掉tomcat服务，那么无法访问了

##### Tomcat的缺省端口是多少，怎么修改

- 默认8080

- 修改端口号方式

  1. 找到Tomcat目录下的conf文件夹
  2. 进入conf文件夹里面找到server.xml文件
  3. 打开server.xml文件
  4. 在server.xml文件里面找到下列信息
  5. 把Connector标签的8080端口改成你想要的端口

  ```properties
  <Service name="Catalina">
  <Connector port="8080" protocol="HTTP/1.1" 
                 connectionTimeout="20000" 
                 redirectPort="8443" />
  ```


##### 怎么在Linux上安装Tomcat

1. 先去下载Tomcat的安装包，gz结尾的（代表Linux上的Tomcat）
2. 上传到Linux上，解压
3. 修改端口号，也可以不修改把。如果要修改在server.xml内改
4. 修改好了之后，你就进入你这个tomcat下的bin目录，输入：./startup.sh
   这样就启动成功了。

##### 怎么在Linux部署项目

- 先使用eclipse或IDEA把项目打成.war包，然后上传到Linux服务器，然后把项目放在Tomcat的bin目录下的webapps，在重启Tomcat就行了。

##### Tomcat的目录结构

- /bin：存放用于启动和暂停Tomcat的脚本
- /conf：存放Tomcat的配置文件
- /lib：存放Tomcat服务器需要的各种jar包
- /logs：存放Tomcat的日志文件
- /temp：Tomcat运行时用于存放临时文件
- /webapps：web应用的发布目录
- /work：Tomcat把有jsp生成Servlet防御此目录下

##### 类似Tomcat，发布jsp运行的web服务器还有那些：

- 1、Resin
  Resin提供了最快的jsp/servlets运行平台。在java和javascript的支持下，Resin可以为任务灵活选用合适的开发语言。Resin的一种先进的语言XSL(XML stylesheet language)可以使得形式和内容相分离。
- 2、Jetty
  Jetty是一个开源的servlet容器，它为基于Java的web内容，例如JSP和servlet提供运行环境。Jetty是使用Java语言编写的，它的API以一组JAR包的形式发布。开发人员可以将Jetty容器实例化成一个对象，可以迅速为一些独立运行（stand-alone）的Java应用提供网络和web连接。
- 3、WebLogic
  BEA WebLogic是用于开发、集成、部署和管理大型分布式Web应用、网络应用和数据库应用的Java应用服务器。将Java的动态功能和Java Enterprise标准的安全性引入大型网络应用的开发、集成、部署和管理之中。
- 4、jboss
  Jboss是一个基于J2EE的开放源代码的应用服务器。 JBoss代码遵循LGPL许可，可以在任何商业应用中免费使用，而不用支付费用。JBoss是一个管理EJB的容器和服务器，支持EJB 1.1、EJB 2.0和EJB3的规范。但JBoss核心服务不包括支持servlet/JSP的WEB容器，一般与Tomcat或Jetty绑定使用。

##### tomcat 如何优化？

1. 改Tomcat最大线程连接数
   需要修改conf/server.xml文件，修改里面的配置文件：
   maxThreads=”150”//Tomcat使用线程来处理接收的每个请求。这个值表示Tomcat可 创建的最大的线程数。默认值200。可以根据机器的时期性能和内存大小调整，一般 可以在400-500。最大可以在800左右。
2. Tomcat内存优化,启动时告诉JVM我要多大内存
   调优方式的话，修改：
   Windows 下的catalina.bat
   Linux 下的catalina.sh
   修改方式如:
   JAVA_OPTS=’-Xms256m -Xmx512m’-Xms JVM初始化堆的大小-Xmx JVM堆的最大值 实际参数大

##### tomcat 有哪几种Connector 运行模式(优化)？

**下面，我们先大致了解Tomcat Connector的三种运行模式。**

1. **BIO：同步并阻塞** 一个线程处理一个请求。缺点：并发量高时，线程数较多，浪费资源。Tomcat7或以下，在Linux系统中默认使用这种方式。
   **配制项**：protocol=”HTTP/1.1”

2. **NIO：同步非阻塞IO**
   利用Java的异步IO处理，可以通过少量的线程处理大量的请求，可以复用同一个线程处理多个connection(多路复用)。

   Tomcat8在Linux系统中默认使用这种方式。
   Tomcat7必须修改Connector配置来启动。
   **配制项**：protocol=”org.apache.coyote.http11.Http11NioProtocol”
   **备注**：我们常用的Jetty，Mina，ZooKeeper等都是基于java nio实现.

3. APR：即Apache Portable Runtime，从操作系统层面解决io阻塞问题。
   **AIO方式**，**异步非阻塞IO**(Java NIO2又叫AIO) 主要与NIO的区别主要是操作系统的底层区别.可以做个比喻:比作快递，NIO就是网购后要自己到官网查下快递是否已经到了(可能是多次)，然后自己去取快递；AIO就是快递员送货上门了(不用关注快递进度)。

   **配制项**：protocol=”org.apache.coyote.http11.Http11AprProtocol”
   **备注**：需在本地服务器安装APR库。Tomcat7或Tomcat8在Win7或以上的系统中启动默认使用这种方式。Linux如果安装了apr和native，Tomcat直接启动就支持apr。

##### Tomcat有几种部署方式？

**在Tomcat中部署Web应用的方式主要有如下几种：**

1. 利用Tomcat的自动部署。

   把web应用拷贝到webapps目录。Tomcat在启动时会加载目录下的应用，并将编译后的结果放入work目录下。

2. 使用Manager App控制台部署。

   在tomcat主页点击“Manager App” 进入应用管理控制台，可以指定一个web应用的路径或war文件。

3. 修改conf/server.xml文件部署。

   修改conf/server.xml文件，增加Context节点可以部署应用。

4. 增加自定义的Web部署文件。

   在conf/Catalina/localhost/ 路径下增加 xyz.xml文件，内容是Context节点，可以部署应用。

##### tomcat容器是如何创建servlet类实例？用到了什么原理？

1. 当容器启动时，会读取在webapps目录下所有的web应用中的web.xml文件，然后对 **xml文件进行解析，并读取servlet注册信息**。然后，将每个应用中注册的servlet类都进行加载，并通过 **反射的方式实例化**。（有时候也是在第一次请求时实例化）
2. 在servlet注册时加上1如果为正数，则在一开始就实例化，如果不写或为负数，则第一次请求实例化。

##### Tomcat工作模式

- Tomcat作为servlet容器，有三种工作模式：
  - 1、独立的servlet容器，servlet容器是web服务器的一部分；
  - 2、进程内的servlet容器，servlet容器是作为web服务器的插件和java容器的实现，web服务器插件在内部地址空间打开一个jvm使得java容器在内部得以运行。反应速度快但伸缩性不足；
  - 3、进程外的servlet容器，servlet容器运行于web服务器之外的地址空间，并作为web服务器的插件和java容器实现的结合。反应时间不如进程内但伸缩性和稳定性比进程内优；
- 进入Tomcat的请求可以根据Tomcat的工作模式分为如下两类：
  - Tomcat作为应用程序服务器：请求来自于前端的web服务器，这可能是Apache, IIS, Nginx等；
  - Tomcat作为独立服务器：请求来自于web浏览器；

#### 外键

优点：保持数据一致性（保证数据的引用完整性），子表有主表的外键数据，那么删除表A就会失败。

缺点：更新子表或者删除子表数据都会去主表判断一下，这是个隐式操作，拖累系统，性能很差。

正方观点：
1，由数据库自身保证数据一致性，完整性，更可靠，因为程序很难100％保证数据的完整性，而用外键即使在数据库服务器当机或者出现其他问题的时候，也能够最大限度的保证数据的一致性和完整性。
eg：数据库和应用是一对多的关系，Ａ应用会维护他那部分数据的完整性，系统一变大时，增加了Ｂ应用，Ａ和Ｂ两个应用也许是不同的开发团队来做的。他们如何协调保证数据的完整性，而且一年以后如果又增加了C应用呢？
2，有主外键的数据库设计可以增加ER图的可读性，这点在数据库设计时非常重要。
3，外键在一定程度上说明的业务逻辑，会使设计周到具体全面。

反方观点：
1，可以用触发器或应用程序保证数据的完整性
2，过分强调或者说使用主键／外键会平添开发难度，导致表过多等问题
3，不用外键时数据管理简单，操作方便，性能高（导入导出等操作，在insert,   update,   delete   数据的时候更快）
eg:在海量的数据库中想都不要去想外键，试想，一个程序每天要insert数百万条记录，当存在外键约束的时候，每次要去扫描此记录是否合格，一般还不 止一个字段有外键，这样扫描的数量是成级数的增长！我的一个程序入库在3个小时做完，如果加上外键，需要28个小时！  

结论：
1，在大型系统中（性能要求不高，安全要求高），使用外键；在大型系统中（性能要求高，安全自己控制），不用外键；小系统随便，最好用外键。
2，用外键要适当，不能过分追求
3，不用外键而用程序控制数据一致性和完整性时，应该写一层来保证，然后个个应用通过这个层来访问数据库。

需要注意的是：MySQL允许使用外键，但是为了完整性检验的目的，在除了InnoDB表类型之外的所有表类型中都忽略了这个功能。这可能有些怪异，实际上却非常正常：对于数据库的所有外键的每次插入、更新和删除后，进行完整性检查是一个耗费时间和资源的过程，它可能影响性能，特别是当处理复杂的或者是缠绕的连接树时。因而，用户可以在表的基础上，选择适合于特定需求的最好结合。所以，如果需要更好的性能，并且不需要完整性检查，可以选择使用MyISAM表类型，如果想要在MySQL中根据参照完整性来建立表并且希望在此基础上保持良好的性能，最好选择表结构为innoDB类型

#### [索引](https://blog.csdn.net/tongdanping/article/details/79878302?ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522161059246216780277026060%252522%25252C%252522scm%252522%25253A%25252220140713.130102334..%252522%25257D&request_id=161059246216780277026060&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~baidu_landing_v2~default-2-79878302.pc_v2_rank_blog_default&utm_term=%E7%B4%A2%E5%BC%95)

###### **优缺点：**

**优势：**可以快速检索，减少I/O次数，加快检索速度；根据索引分组和排序，可以加快分组和排序；

**劣势：**索引本身也是表，因此会占用存储空间，一般来说，索引表占用的空间的数据表的1.5倍；索引表的维护和创建需要时间成本，这个成本随着数据量增大而增大；构建索引会降低数据表的修改操作（删除，添加，修改）的效率，因为在修改数据表的同时还需要修改索引表；



###### 分类

**常见的索引类型有：主键索引、唯一索引、普通索引、全文索引、组合索引**

1、主键索引：即主索引，根据主键pk_clolum（length）建立索引，**不允许重复，不允许空值**；

```sql
ALTER TABLE 'table_name' ADD PRIMARY KEY pk_index('col')；
```

2、唯一索引：用来建立索引的列的值必须是**唯一的，允许空值**

```sql
ALTER TABLE 'table_name' ADD UNIQUE index_name('col')；
```

3、普通索引：用表中的普通列构建的索引，没有任何限制

```sql
ALTER TABLE 'table_name' ADD INDEX index_name('col')；
```

4、全文索引：用大文本对象的列构建的索引（下一部分会讲解）

```sql
ALTER TABLE 'table_name' ADD FULLTEXT INDEX ft_index('col')；
```

5、组合索引：用多个列组合构建的索引，这多个列中的值不允许有空值

```sql
ALTER TABLE 'table_name' ADD INDEX index_name('col1','col2','col3')；
```

*遵循“最左前缀”原则，把最常用作为检索或排序的列放在最左，依次递减，组合索引**相当于建立了col1,col1col2,col1col2col3三个索引**，而col2或者col3是不能使用索引的。

*在使用组合索引的时候可能因为列名长度过长而导致索引的key太大，导致效率降低，在允许的情况下，可以只取col1和col2的前几个字符作为索引

```sql
ALTER TABLE 'table_name' ADD INDEX index_name(col1(4),col2（3))；
```

表示使用col1的前4个字符和col2的前3个字符作为索引

###### **B+Tree对比BTree的优点：**

1、磁盘读写代价更低

一般来说B+Tree比BTree更适合实现外存的索引结构，因为存储引擎的设计专家巧妙的利用了外存（磁盘）的存储结构，即磁盘的最小存储单位是扇区（sector），而操作系统的块（block）通常是整数倍的sector，操作系统以页（page）为单位管理内存，一页（page）通常默认为4K，数据库的页通常设置为操作系统页的整数倍，因此索引结构的节点被设计为一个页的大小，然后利用外存的“预读取”原则，每次读取的时候，把整个节点的数据读取到内存中，然后在内存中查找，已知内存的读取速度是外存读取I/O速度的几百倍，那么**提升查找速度的关键就在于尽可能少的磁盘I/O，那么可以知道，每个节点中的key个数越多，那么树的高度越小，需要I/O的次数越少，因此一般来说B+Tree比BTree更快，因为B+Tree的非叶节点中不存储data，就可以存储更多的key**。

2、查询速度更稳定

由于B+Tree非叶子节点不存储数据（data），因此所有的数据都要查询至叶子节点，而叶子节点的高度都是相同的，因此所有数据的查询速度都是一样的。

###### 聚簇索引和非聚簇索引

**MyISAM——非聚簇索引**

- MyISAM存储引擎采用的是非聚簇索引，非聚簇索引的**主索引和辅助索引几乎是一样的**，只是主索引不允许重复，不允许空值，他们的**叶子结点的key都存储指向键值对应的数据的物理地址**。
- 非聚簇索引的**数据表和索引表是分开存储**的。
- 非聚簇索引中的数据是根据数据的插入顺序保存。因此非聚簇索引更适合单个数据的查询。插入顺序不受键值影响。
- 只有在MyISAM中才能使用FULLTEXT索引。(mysql5.6以后innoDB也支持全文索引)

**InnoDB——聚簇索引**

- 聚簇索引的**主索引的叶子结点存储的是键值对应的数据本身，辅助索引的叶子结点存储的是键值对应的数据的主键键值**。因此主键的值长度越小越好，类型越简单越好。
- 聚簇索引的**数据和主键索引存储在一起**。
- 聚簇索引的数据是根据主键的顺序保存。因此适合按主键索引的区间查找，可以有更少的磁盘I/O，加快查询速度。但是也是因为这个原因，聚簇索引的插入顺序最好按照主键单调的顺序插入，否则会频繁的引起页分裂，严重影响性能。
- 在InnoDB中，如果只需要查找索引的列，就尽量不要加入其它的列，这样会提高查询效率。

|              | MyISAM           | innoDB                           |
| ------------ | ---------------- | -------------------------------- |
| 索引类型     | 非聚簇           | 聚簇                             |
| 支持事务     | 是               | 否                               |
| 支持表锁     | 是               | 是                               |
| 支持行锁     | 否               | 是（默认）                       |
| 支持外键     | 否               | 是                               |
| 支持全文索引 | 是               | 是（5.6以后支持）                |
| 适用操作类型 | 大量select下使用 | 大量insert、delete和update下使用 |

- InnoDB 支持事务，支持行级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引；
- MyISAM 不支持事务，支持表级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引；

此外，Memory 不支持事务，支持表级别锁定，支持 B-tree、Hash 等索引，不支持 Full-text 索引；